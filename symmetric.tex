\documentclass[12pt]{article}

\usepackage{amssymb,amsmath,amsthm}
\usepackage{ytableau}

% theorem styles (I like everything to have the same counter)
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{exercise}[theorem]{Exercise}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% some numbering settings
\numberwithin{equation}{section}

\usepackage{fancyhdr}
\usepackage{lastpage}
\setlength{\headheight}{15.2pt}
\renewcommand{\footrulewidth}{0.4pt}% default is 0pt
\setlength{\footskip}{30pt}
\pagestyle{fancy}

\makeatletter
\let\ps@plain\ps@fancy 
\makeatother

\lhead{MATH 742}
\chead{$S_n$ and $\operatorname{GL}_n$}
\rhead{Spring 2023}
\lfoot{Last Revised: \today}
\cfoot{}
\rfoot{\thepage\ of \pageref{LastPage} }

\begin{document}

%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
\title{Symmetric Groups and General Linear Groups}
\author{Alexander Duncan}

\maketitle

Here we discuss the theory of symmetric functions, with the particular
goal of describing representations of the symmetric groups and general
linear groups.
The irreducible representations of the symmetric group
$S_n$ are the \emph{Specht modules} $V_\lambda$, which are parametrized
by the partitions $\lambda$ of weight $n$.
The irreducible polynomial representations of the general linear group
$\operatorname{GL}(\mathbb{V})$ are precisely the (images of the)
\emph{Schur functors} $\mathbb{S}_\lambda(V)$ where $\lambda$ is
partition of length $\ell(\lambda) \le \dim(V)$.
Both are best understood as being in bijection with \emph{Schur
functions} $\{ s_\lambda \}$, which form an orthonormal basis for the
ring of symmetric functions. 

These notes are not self-contained.  Many proofs will be sketched or
left as a reference.  This is not because the proofs are hard (the
beauty of this subject is that they are often very slick!), but that the
theory is too rich to properly explore in only a few weeks.
Much of this material is drawn from
\cite[\S{4,6,A}]{FultonHarris},
\cite[\S{5.12--5.19}]{Etingof},
\cite[\S{I}]{Macdonald}, and
\cite[\S{7}]{Stanley2}.

%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%

\section{Partitions}

Recall that a \emph{partition} $\lambda$ is a sequence of non-strictly decreasing
non-negative integers
$\lambda_1 \ge \lambda_2 \ge \cdots$ that is eventually $0$.
Some standard terminology:
\begin{itemize}
\item The non-zero $\lambda_i$ are the \emph{parts} of $\lambda$.
\item The number $\ell(\lambda)$ of parts is the \emph{length} of $\lambda$.
\item The sum $|\lambda|=\sum_{i \ge 0} \lambda_i$ is the \emph{weight} of $\lambda$.
\item A ``partition of $n$'' is a partition of weight $n$.
\item $\lambda \vdash n$ means $\lambda$ is a partition of $n$.
\item The number $m_i(\lambda)$ of parts equal to $i$ is
the \emph{multiplicity} of $i$ in $\lambda$.
\item Partitions can be written $\lambda_1 + \lambda_2 + \cdots + \lambda_r$.
\item We may use the shorthand $\lambda = (1^{m_1} 2^{m_2} \cdots r^{m_r})$.
\item $\lambda+\mu$ is the partition $(\lambda_1+\mu_1, \ldots)$.
\item $\lambda \subseteq \mu$ means $\lambda_i \le \mu_i$ for all $i \ge 1$.
\item The dominance ordering $\lambda \le \mu$ means
$\sum_{j=1}^i\lambda_j \le \sum_{j=1}^i\mu_j$ for all $i \ge 1$.
\end{itemize}

Partitions are often drawn as \emph{Young diagrams}.  This is just a
series of empty boxes where each row contains $\lambda_i$ boxes.
We use \emph{English notation} where $\lambda_1$ is the top row.
There are some differing conventions between different areas of math, so
read any source carefully.

Given a partition $\lambda$, the \emph{conjugate partition}
is the partition $\lambda^\dag$ obtained by reflecting the Young diagram in
the downwards-right diagonal line.  More explicitly,
$\lambda^\dag_i$ is the number of parts such that $\lambda_j \ge i$. 

\begin{example}
The partitions of $4$ are as follows:
\begin{center}
\begin{tabular}{ccccc}
4 & 3+1 & 2+2 & 2+1+1 & 1+1+1+1 \\
\ydiagram{4} & \ydiagram{3,1} & \ydiagram{2,2} & \ydiagram{2,1,1} &
\ydiagram{1,1,1,1}
\end{tabular}
\end{center}
\end{example}

\begin{example}
Let $\lambda = (4,4,2,2,2,1)$.
We may also write $\lambda$ as $4+4+2+2+2+1$ or $1^12^34^2$.
We have parts $\lambda_1=4$, $\lambda_2=4$,
$\lambda_3=2$,
$\lambda_4=2$,
$\lambda_5=2$, and
$\lambda_6=1$.
We have length $\ell(\lambda)=6$, weight $|\lambda|=15$,
and multiplicities $m_1(\lambda)=1$, $m_2(\lambda)=3$,
$m_3(\lambda)=0$, and $m_4(\lambda)=2$.
The Young tableau is
\begin{center}
\ydiagram{4,4,2,2,2,1}.
\end{center}
The conjugate partition $\lambda^\dag$ is $(6,5,2,2)$.
\end{example}

Recall that every permutation $\sigma \in S_n$ can be written as a
product of disjoint cycles, which is unique up to reordering of
the cycles.  Counting the cycles of length $1$, we see that the orders
of the constituent cycles give a partition $\lambda \vdash n$.
For example $(1\ 4\ 3)(2\ 8)(6\ 7) \in S_9$ has cycle type
$3+2+2+1+1$.
The following is standard in most group theory texts:

\begin{proposition}
Two permutations in $S_n$ are conjugate if and only if they have the
same cycle type.
In particular, the conjugacy classes of $S_n$ are in canonical bijective
correspondence with partitions of $n$.
\end{proposition}

For every partition $\lambda$, we define the integers
\[
\epsilon_\lambda = (-1)^{|\lambda|-\ell(\lambda)} .
\]
and
\[
z_\lambda = \prod_{i \ge 1} i^{m_i} m_i!
\]
where $m_i=m_i(\lambda)$ denotes the multiplicities,

\begin{exercise}
Prove that, if $\sigma \in S_n$ has cycle type $\lambda$,
then $\operatorname{sgn}(\sigma)=\epsilon_\lambda$.
\end{exercise}

\begin{exercise}
Prove that, if $\sigma \in S_n$ has cycle type $\lambda$,
then the centralizer $Z_{S_n}(\sigma)$ has order $z_\lambda$.
Equivalently, the number of elements of $S_n$ with cycle type $\lambda$
is $n!/z_\lambda$.
\end{exercise}

\section{Symmetric Polynomials}

There is a natural left action of the symmetric group $S_n$ on the ring of
polynomials $R=\mathbb{Z}[x_1,\ldots,x_n]$ by permuting the variables.
More precisely, there is a unique ring automorphism of $R$ defined
by $x_i \mapsto x_{\sigma(i)}$ for each variable $x_i$ and each
permutation $\sigma \in S_n$.
Alternatively, if $\sigma \in S_n$, the we have
\[
(\sigma \cdot f)(a_1,\ldots,a_n) =
f\left(a_{\sigma(1)}, \ldots, a_{\sigma}(n)\right)
\]
for $f \in R$ and $a_1,\ldots,a_n \in \mathbb{Z}$.

\begin{definition}
A polynomial $f \in \mathbb{Z}[x_1,\ldots, x_n]$ is \emph{symmetric}
if $\sigma \cdot f = f$ for all $\sigma \in \Sigma$.
We denote by $\mathsf{SF}_n$ the set of symmetric polynomials
$\mathbb{Z}[x_1,\ldots,x_n]^{S_n}$ in $n$ variables.
\end{definition}

The set $\mathsf{SF}_n$ forms a graded ring
\[
\mathsf{SF}_n = \bigoplus_{d \ge 0} \mathsf{SF}_n^d
\]
where each $\mathsf{SF}_n^d = \mathbb{Z}[x_1,\ldots,x_n]_{(d)}^{S_n}$
is the subgroup of homogeneous symmetric polynomials of degree $d$.

Given a tuple $\alpha = (\alpha_1,\ldots,\alpha_n) \in \mathbb{N}^n$
we use the shorthand
\[
x^\alpha = x_1^{\alpha_1} \cdots x_n^{\alpha_n}
\]
to denote monomials in $\mathbb{Z}[x_1,\ldots,x_n]$.

Given a partition $\lambda \vdash d$ with length $\ell(\lambda) \le n$,
the \emph{monomial symmetric polynomial associated to $\lambda$}
is given by
\[
m_\lambda := \sum_{\alpha} x^\alpha
\]
where $(\alpha_1,\ldots,\alpha_n)$ ranges over all
\emph{distinct} permutations of $(\lambda_1,\ldots,\lambda_n)$.

\begin{exercise}
Prove that $\displaystyle z_\lambda m_\lambda = \sum_{\sigma \in S_n}
x^{\sigma(\lambda)}$ for all $\lambda$ of length $\ell(\lambda) \le n$.
\end{exercise}

\begin{example}
If $n=3$, then we have
\begin{align*}
m_\emptyset &= 1\\
m_1 &= x_1 + x_2 + x_3\\
m_2 &= x_1^2 + x_2^2 + x_3^2\\
m_{11} &= x_1x_2 + x_1x_3 + x_2x_3\\
m_{111} &= x_1x_2x_3 \\
m_{14} &= x_1x_2^4 + x_1^4x_2 + x_1x_3^4 + x_1^4x_3 + x_2x_3^4 +
x_2^4x_3.
\end{align*}
\end{example}

Importantly, we have the following:

\begin{proposition}
Monomial symmetric polynomials form a basis for $\mathsf{SF}_n$.
Specifically,
\[
\mathsf{SF}_n^d = \operatorname{span}_{\mathbb{Z}}
\{ m_\lambda \mid \lambda \vdash d, \ell(\lambda) \le n \}.
\]
\end{proposition}

\begin{proof}
The partitions of length at most $n$ are a system of distinct
representatives for the $S_n$-orbits of $\mathbb{N}^n$.
The monomials in $m_\lambda$ are precisely those of the orbit of
$\lambda$.
The coefficient of every monomial
in $m_\lambda$ is either $0$ or $1$ and every possible monomial
occurs in exactly one $m_\lambda$.
If $f$ is a symmetric polynomial, then the coefficient
of a monomial $x^\alpha$ must be the same as $x^{\sigma(\alpha)}$
for every $\sigma \in S_n$.  
\end{proof}

There are several notable additional families of symmetric polynomials
which we define now.

\begin{definition}
For positive integers $d$, we define
the \emph{elementary symmetric polynomial $e_d$ of degree $d$} as
\[
e_d = m_{1^d} = \sum_{1 \le i_1 < i_2 < \cdots < i_d \le n} x_{i_1}x_{i_2}\cdots
x_{i_d},
\]
the \emph{complete homogeneous symmetric polynomial $h_d$ of degree $d$} as
\[
h_d = \sum_{\lambda \vdash d} m_\lambda = \sum_{1 \le i_1 \le i_2 \le \cdots \le i_d \le n} x_{i_1}x_{i_2}\cdots
x_{i_d},
\]
and the \emph{power sum symmetric polynomial $p_d$ of degree $d$} as
\[
p_d = m_d = \sum_{1 \le i \le n} x_i^d.
\]
By convention, $e_0=h_0=p_0=1$.
\end{definition}

\begin{remark}
The conventions for $e_0$ and $h_0$ are uncontroversial,
but many references leave $p_0$ undefined.
Indeed, there are good reasons to instead define $p_0=n$, but this does not
extend to the ring of symmetric functions discussed below. 
\end{remark}

\begin{example}
If $n=3$, then we have
\begin{align*}
e_1 = h_1 = p_1 &= x_1 + x_2 + x_3\\
e_2 &= x_1x_2 + x_1x_3 + x_2x_3\\
e_3 &= x_1x_2x_3 \\
e_4 &= 0 \\
h_2 &= x_1^2 + x_2^2 + x_3^2 + x_1x_2 + x_1x_3 + x_2x_3\\
h_3 &= x_1^3 + \cdots + x_1^2x_2 + \cdots + x_1x_2x_3\\
p_2 &= x_1^2 + x_2^2 + x_3^2\\
p_3 &= x_1^3 + x_2^3 + x_3^3
\end{align*}
\end{example}

It is worth mentioning right away (but whose proof we will defer)
some fundamental results.  First, we have \emph{Newton's identities}:
\[
de_d = \sum_{i=1}^d (-1)^{i-1} p_i e_{d-i} ,
\]
and the fundamental relation
\[
0 = \sum_{i=0}^d (-1)^i e_i h_{d-i},
\]
which hold for all positive integers $d$.
These allow one to recursively compute $p_i$'s and $h_i$'s in terms
of $e_i$'s (and vice versa).

We also have the \emph{Fundamental Theorem of Symmetric
Polynomials} which states that $e_1,\ldots,e_n$ are algebraically independent
generators of the ring $\mathsf{SF}_n$.
In fact, combining this with the above relations, we have
\begin{align*}
\mathbb{Z}[x_1,\ldots,x_n]^{S_n} &= \mathbb{Z}[e_1,\ldots,e_n]\\
\mathbb{Z}[x_1,\ldots,x_n]^{S_n} &= \mathbb{Z}[h_1,\ldots,h_n]\\
\mathbb{Q}[x_1,\ldots,x_n]^{S_n} &= \mathbb{Q}[p_1,\ldots,p_n]
\end{align*}
where rational coefficients are necessary for the last equality.
The proofs of these equalities are not very hard, but we defer them for
the moment as they are consequences of more general facts.

\subsection{Alternating and Schur Polynomials}

Let $\epsilon : S_n \to \{\pm 1\}$ be the sign homomorphism
and let $A_n = \ker(\epsilon)$ be the alternating group on $n$ letters.

\begin{definition}
A polynomial $f \in \mathbb{Z}[x_1,\ldots,x_n]$ is \emph{alternating} if
$\sigma \cdot f = \epsilon(\sigma)f$ for all $\sigma \in S_n$.
Given an element $\alpha \in \mathbb{N}^n$, define the \emph{alternant
of $\alpha$} as
\[
a_\alpha = \sum_{\sigma \in S_n} \epsilon(\sigma) x^{\sigma(\alpha)},
\]
which is an alternating polynomial.
\end{definition}

Note that $a_\alpha=0$ if and only if the entries of $\alpha$ are
not distinct.  We also see that every alternating polynomial is a linear
combination of $a_\lambda$'s for partitions $\lambda$ where the parts
$\lambda_i$ are all distinct.
Observe that all parts of $\lambda$ are distinct if and only if
$\delta \subseteq \lambda$ where
$\delta=(n-1,n-2,\ldots,1,0)$.
We have the following:

\begin{lemma}
The set
\[
\{ a_\lambda \mid \ell(\lambda) \le n, \delta \subseteq \lambda \}
\]
is a basis for the group of alternating polynomials.
\end{lemma}

\begin{example}
The \emph{Vandermonde polynomial} $\Delta \in \mathbb{Z}[x_1,\ldots,x_n]$
is defined via
\[
\Delta = \prod_{1 \le i < j \le n} (x_i-x_j).
\]
Note that $(i\ j) \cdot \Delta = -\Delta$ for all $i \ne j$.
We conclude that $\sigma(\Delta) = \operatorname{sgn}(\sigma)$
for all $\sigma \in S_n$.
Thus $\Delta$ is alternating.
Observe that $\Delta=a_\delta$.
\end{example}

\begin{lemma}
Every alternating polynomial $f$ has the form $g \Delta$
where $g$ is a symmetric polynomial. 
\end{lemma}

\begin{proof}
It suffices to show that $(x_i-x_j)$ divides $f$ for all $i \ne j$.
Indeed, suppose $c_\alpha x^\alpha$ is a monomial in $f$
and write $x^\alpha = x_i^u x_j^v x^\beta$ where $x_i$ and $x_j$
do not divide $x^\beta$.
Since $f$ is alternating, $-c_\alpha x_i^v x_j^u x^\beta$
also must appear in $f$.
Thus $c_\alpha (x_i^u x_j^v - x_i^v x_j^u) x^\beta$ occurs in $f$.
Each of these divisible by $(x_i-x_j)$ as desired.
\end{proof}

The following definition now makes sense:

\begin{definition}
For a partition $\lambda$ of length $\le n$, the \emph{Schur polynomial}
is the symmetric polynomial
$s_\lambda = a_{\lambda+\delta}/a_\delta$.
\end{definition}

The alternants $\{ a_{\lambda+\delta} \}$ are a basis for
the alternating polynomials analogously to the monomial symmetric
polynomials $\{ m_\lambda \}$ being a basis for the symmetric
polynomials.
Since we have $a_{\lambda+\delta}=s_\lambda a_\delta$, the Schur polynomials
as ``monomial alternating polynomials'' except we've divided out the
alternating part so that they are symmetric.

In particular, we have the following:

\begin{proposition}
The set of Schur polynomials
\[
\{ s_\lambda \mid \lambda \vdash d, \ell(\lambda) \le n \}
\]
are a basis for $\mathsf{SF}^d_n$.
\end{proposition}

The \emph{Kostka numbers} $K_{\lambda \mu}$ are the entries of the
change of basis matrix between the monomial basis and the Schur basis.
Specifically, they are non-negative integers such that
\[
s_\lambda = \sum_{\substack{\mu\, \vdash |\lambda|\\\ell(\mu) \le n}} K_{\lambda \mu} m_\mu
\]
for all partitions $\lambda,\mu$.  The Kostka numbers do not depend on the number of
variables $n$ in the ambient polynomial ring (we do not prove this here).

\begin{example}
For $n \ge 4$, we have the following change of basis matrix:
\[
\begin{pmatrix}
s_{1111}\\ s_{211} \\ s_{22}\\ s_{31}\\ s_4
\end{pmatrix}
=
\begin{pmatrix}
1 & 0 & 0 & 0 & 0\\
3 & 1 & 0 & 0 & 0\\
2 & 1 & 1 & 0 & 0\\
3 & 2 & 1 & 1 & 0\\
1 & 1 & 1 & 1 & 1
\end{pmatrix} 
\begin{pmatrix}
m_{1111}\\ m_{211} \\ m_{22}\\ m_{31}\\ m_4
\end{pmatrix}
\]
Thus, for example $K_{(31)(1111)}=3$.
\end{example}

\begin{exercise}
Prove that $s_{(d)} = h_d$ and $s_{(1^d)} = e_d$.
\end{exercise}

We will not need the following later, but it is of general interest:

\begin{theorem}[Fundamental Theorem of Alternating Polynomials]
The ring $\mathbb{Z}[x_1,\ldots,x_n]^{A_n}$ is a free
$\mathsf{SF}_n$-module with basis $\{1, \Delta\}$.
In other words, every $A_n$-invariant polynomial $f$ can be written uniquely
as $f=p+\Delta q$ where $p,q$ are symmetric.
\end{theorem}

\begin{remark}
If $V$ is an $n$-dimensional complex linear representation of $G$,
then we have a natural action of $G$ on the polynomial ring
$S=\mathbb{C}[x_1,\ldots,x_n]$ by viewing it as the symmetric algebra
$\mathcal{S}(V^\vee)$.
A famous theorem of Hochster-Roberts proves that the invariant ring
$S^G=\mathbb{C}[x_1,\ldots,x_n]^G$ is a Cohen-Macaulay ring:
there exists a polynomial subring $R=\mathbb{C}[f_1,\ldots,f_n]$
such that $S^G$ is a free $R$-module.
The ``Fundamental Theorem of Alternating Polynomials'' can be seen as a
very special case of this fact (where the subring and basis have
particular interpretations).
\end{remark}

\subsection{Symmetric and Exterior Powers}

We now see some of the connections of symmetric functions and
representation theory:

\begin{proposition}
Suppose $V$ is an $n$-dimensional vector space and
$\varphi \in \operatorname{End}(V)$ has eigenvalues
$\alpha_1,\ldots,\alpha_n$.
Then the natural action of $\varphi$ on the exterior power $\Lambda^d V$
has trace
\[
\operatorname{tr}\left( \Lambda^d \varphi \right)
= e_d(\alpha_1,\ldots,\alpha_n)
\]
and the natural action of $\varphi$ on the symmetric power
$\mathcal{S}^d V$ has trace
\[
\operatorname{tr}\left( \mathcal{S}^d \varphi \right)
= h_d(\alpha_1,\ldots,\alpha_n).
\]
\end{proposition}

\begin{proof}
It suffices to work over an algebraically closed field $k$.
We prove the statement for $\Lambda^d V$ since the argument for
$\mathcal{S}^d$ is very similar. 

First, we assume that $\varphi$ is diagonalizable with eigenvectors
$v_1,\ldots, v_n$ corresponding to eigenvalues
$\alpha_1,\ldots,\alpha_n$.
Now, an eigenbasis for $\Lambda^d V$ is given by
\[
\{ v_{i_1}\wedge v_{i_2}\wedge \cdots \wedge v_{i_d} \mid
1 \le i_1 < i_2 < \cdots < i_d \le n \} \ .
\]
The corresponding eigenvalues of $\Lambda^d \varphi$ are therefore
\[
\{ \alpha_{i_1} \alpha_{i_2} \cdots \alpha_{i_d} \mid
1 \le i_1 < i_2 < \cdots < i_d \le n \} \ .
\]
The trace of $\Lambda^d \phi$ is just the sum of the eigenvalues, which
is $e_d(\alpha_1,\ldots,\alpha_n)$ as desired.

Now we consider the case where $\varphi$ is not diagonalizable.
In this case $\varphi$ has a Jordan canonical form.  Thus,
we have a basis $v_1,\ldots, v_n$ for $V$ such that $\varphi$ is
represented by $D+N$ where $D$ is a diagonal matrix and
$N$ is a lower triangular matrix.
Observe that $N(v_i)$ is a linear combination of $v_{i+1},\ldots, v_n$.

Define a total ordering on $\mathbb{N}^n$ where
$(a_1,\ldots,a_n) < (b_1,\ldots,b_n)$ if $a_i < b_i$ for the minimal $i$
on which $a_i \ne b_i$.
We now observe that
\[
(D+N)(v_{i_1}\wedge \cdots \wedge v_{i_d})
= D(v_{i_1}\wedge \cdots \wedge v_{i_d})
+ \textrm{higher terms} 
\]
where the ``higher terms'' are scalar multiples of
$v_{j_1}\wedge \cdots \wedge v_{j_d}$
where we have $(j_1,\ldots,j_d) > (i_1,\ldots,i_d)$.
Thus, appropriately ordered, our basis for $\Lambda^d V$
also represents $\Lambda^d V$ as a lower-triangular matrix.
The trace only depends on the diagonal entries so the result follows
from the diagonalizable case.
\end{proof}

Another way of understanding the previous proposition is that
$\Lambda^d V$ and $\mathcal{S}^d V$ are representations of
$\operatorname{GL}(V)$ with corresponding characters $e_d$ and
$h_d$, respectively.
We will see that there is a class of symmetric polynomials
called \emph{Schur polynomials} which are precisely the characters
of the irreducible \emph{polynomial} representations of
$\operatorname{GL}(V)$.


\section{The Ring of Symmetric Functions}

Many of the relations between various special symmetric polynomials are
basically independent of the number $n$ of variables $x_1,\ldots,x_n$
in the ambient polynomial ring.  The \emph{ring of symmetric functions}
is a standard object in algebraic combinatorics that facilitates
this.  Several equivalent constructions exist, but we will follow
the construction from \cite{Stanley2}, which is fairly down to earth.

Let $\mathbb{Z}[[\{x_n\}_{n \in \mathbb{N}_{>0}}]]$ be the ring of formal
power series in countably many variables.  Recall that this means that
we allow only finitely many $x_i$ in each monomial, but each element may be
a linear combination of infinitely many monomials and there may be no upper
bound on the subscripts $i$ occurring among the $x_i$'s in each
monomial.
For a non-negative integer $d$, the subgroup
$\mathbb{Z}[[\{x_n\}_{n \in \mathbb{N}_{>0}}]]_{(d)}$ consists of those
elements whose monomials all have degree exactly $d$ (in other words,
exactly $d$ variables $x_i$ in each monomial, counting multiplicities).

Let $S_{\mathbb{N}_{>0}}$ be the symmetric group on $\mathbb{N}_{>0}$; in other
words, the group of all bijections $\mathbb{N}_{>0} \to \mathbb{N}_{>0}$.
There is a natural action of $S_{\mathbb{N}_{>0}}$ on
$\mathbb{Z}[[\{x_n\}_{n \in \mathbb{N}_{>0}}]]$ by permuting variables that
preserves the degree.
A \emph{homogeneous symmetric function of degree $d$} is an element
$f \in \mathbb{Z}[[\{x_n\}_{n \in \mathbb{N}_{>0}}]]_{(d)}^{S_{\mathbb{N}}}$.
Let $\mathsf{SF}^d$ be the subgroup of
homogeneous symmetric functions of degree $d$.

We define the \emph{ring of symmetric functions} as the (internal) direct sum
\[
\mathsf{SF} = \bigoplus_{d \ge 0} \mathsf{SF}^d,
\]
which is a graded subring of $\mathbb{Z}[[\{x_n\}_{n \in \mathbb{N}_{>0}}]]$.

\begin{remark}
Note that ``symmetric function'' is standard terminology,
but it's not a great name since it's not
really clear what it is a function \emph{of}.
Moreover, the term symmetric function is often used in the finite
variable case to discuss ``ordinary'' functions like $e^{x+y}$,
which are invariant under symmetries like $x \leftrightarrow y$.
\end{remark}

There are canonical surjective graded ring homomorphisms
$\rho_n : \mathsf{SF} \to \mathsf{SF}_n$, which are defined via
\[
\rho_n(f)(x_1,\ldots,x_n) = f(x_1,\ldots,x_n,0,0,\cdots) .
\]
Note that convergence is not an issue since all but finitely many monomials
will evaluate as zero.

\begin{remark}
One can equivalently define the ring of symmetric functions as an inverse
limit
\[
\mathsf{SF} = \lim_{\substack{\longleftarrow\\n}} \mathsf{SF}^n
\]
in the category of graded rings (see \cite{Macdonald}).
(Warning: it is \emph{not} the inverse limit in ordinary rings.)
The $\rho_n$ above are precisely the canonical projections obtained from
this construction.
\end{remark}

We define the \emph{monomial symmetric function associated to $\lambda$}
given by
\[
m_\lambda := \sum_{\alpha} x^\alpha
\]
where $(\alpha_1,\ldots) \in \mathbb{N}^{\mathbb{N}_{>0}}$ ranges over all
\emph{distinct} permutations of $(\lambda_1,\ldots)$.
Observe that the set $\{ m_\lambda\}$ is a basis for $\mathsf{SF}$.

We can now define the \emph{elementary symmetric functions}
\[
e_d = m_{1^d},
\]
the \emph{complete homogeneous symmetric functions}
\[
h_d = \sum_{\lambda \vdash d} m_\lambda ,
\]
and the \emph{power sum symmetric functions}
\[
p_d = m_{d}.
\]

The overloading of $m_\lambda$, $e_d$, $h_d$, and $p_d$ to mean
different objects in each $\mathsf{SF}^n$ is seen to be mostly harmless
in view of the fact that they are precisely the images of the
corresponding objects in $\mathsf{SF}$ under the maps to $\rho_n$.

We may also define the \emph{Schur symmetric functions}
$s_\lambda$ via 
\[
s_\lambda = \sum_{\mu} K_{\lambda \mu} m_\mu
\]
by taking advantage of the fact that the Kostka numbers
do not depend on the number of variables in the given polynomial ring.

\subsection{Relations and Identities}

\begin{proposition} \label{prop:fund_rel}
$\displaystyle\sum_{i=0}^d (-1)^i e_i h_{d-i}=0$ for every $d \ge 1$.
\end{proposition}

\begin{proof}
Consider the generating functions
\[ E(t) = \sum_{r \ge 0} e_r t^r
\textrm{ and }
H(t) = \sum_{r \ge 0} h_r t^r \]
as elements in $\mathsf{SF}[[t]]$.
We see that
\begin{align*}
& E(t)\\
 =& 1 + (x_1+x_2+\cdots)t
+ (x_1x_2+x_1x_3+\cdots)t^2 \\
=&\prod_{i \ge 1} (1+x_i t)
\end{align*}
in the larger ring $\mathbb{Z}[[x_1,\ldots]][[t]]$.
Similarly, recalling the geometric series formula, we have
\[
H(t) = \prod_{i \ge 1} (1-x_i t)^{-1} .
\]
The equality $H(t)E(-t)=1$ is immediate.
The desired identities are simply the coefficients of $t^d$
in this equality.
\end{proof}

\begin{proposition}[Newton Identities] For all $d \ge 1$,
\begin{align*}
dh_d&=\sum_{i=1}^d p_i h_{d-i} \textrm{ and} \\ 
de_d&=\sum_{i=1}^d (-1)^{i-1} p_i e_{d-i}.
\end{align*}
\end{proposition}

\begin{proof}
We compute
\begin{align*}
\sum_{r \ge 1} p_r t^{r-1}
&= \sum_{i \ge 1} \sum_{d \ge 0} x_i^d t^{d-1}
= \sum_{i \ge 1} \frac{x_i}{1-x_it}\\
&= \sum_{i \ge 1} \frac{d}{dt}\log\left(
\left(1-x_i\right)^{-1}\right)
= \frac{H'(t)}{H(t)} = \frac{E'(-t)}{E(-t)}
\end{align*}
and then we read the identities off from 
the coefficients of $t^d$ in $P(t)H(t)=H'(t)$
and $P(t)E(-t)=E'(-t)$.
\end{proof}

For $\lambda=(\lambda_1,\lambda_2,\ldots,\lambda_r)$ we define
$e_\lambda = e_{\lambda_1}\cdot e_{\lambda_2} \cdots e_{\lambda_r}$,
$h_\lambda = h_{\lambda_1}\cdot h_{\lambda_2} \cdots h_{\lambda_r}$, and
$p_\lambda = p_{\lambda_1}\cdot p_{\lambda_2} \cdots p_{\lambda_r}$.

Recall the \emph{dominance partial ordering} on partitions where $\lambda \ge \mu$
if and only if
$\lambda_1 + \cdots + \lambda_i \ge \mu_1 + \cdots \mu_i$
for all $i \ge 1$.
(Note this is only a partial ordering as, for example, $(31^3)$ and $(2^3)$
are incomparable.

\begin{proposition} \label{prop:01matrix}
We have
\[
e_\lambda = \sum_{\mu \vdash |\lambda|} M_{\lambda \mu} m_\mu
\]
where $M_{\lambda \mu}$ is the number of $\{0,1\}$-matrices whose
rows sum to $\lambda_1,\lambda_2,\ldots$ and whose columns
sum to $\mu_1,\mu_2,\ldots$.
Moreover, $M_{\lambda\mu} \ne 0$ if and only if $\mu \le \lambda^\dag$
and $M_{\lambda\lambda^\dag}=1$.
\end{proposition}

\begin{proof}
We merely sketch the argument.
We consider the terms of $e_\lambda$ and $m_\mu$ in reference to the
following matrix:
\[
X = \begin{pmatrix}
x_1 & x_2 & x_3 & \cdots \\
x_1 & x_2 & x_3 & \cdots \\
x_1 & x_2 & x_3 & \cdots \\
\vdots & \vdots & \vdots & \ddots
\end{pmatrix}.
\]
Observe that each $\{0,1\}$-matrix $Y$ produces a monomial $x^\alpha$
by taking the product of the entries of $X$ corresponding to the
non-zero entries of $Y$.
Monomials in $e_\lambda$ are uniquely constructed by
taking the product of exactly $\lambda_1$ distinct entries from row $1$,
exactly $\lambda_2$ from row $2$, etc.
Monomials $x^\mu$ are constructed by
taking the product of exactly $\mu_1$ distinct entries from column $1$,
exactly $\mu_2$ from column $2$, etc.

The conditions on $M_{\lambda\mu}$ now follow by looking for
$\{0,1\}$-matrices satisfying certain constraints.
\end{proof}

After refining our partial order to a total order
on the partitions, we can think of $M=\left(M_{\lambda\mu}\right)$ as
an infinite integer matrix.
Note that $M_{\lambda\mu^\dag}$ is triangular with $1$s along the diagonal.
Thus $M$ is invertible and we have the following important corollary:

\begin{corollary}[Fundamental Theorem of Symmetric Functions]
There is an equality of rings
\[\mathsf{SF} = \mathbb{Z}[e_1,e_2,\ldots] \]
where $e_1,e_2,\ldots$ are algebraically independent.
\end{corollary}

\begin{exercise}
Find an analog for Proposition~\ref{prop:01matrix} for $h_\lambda$
using $\mathbb{N}$-matrices instead of $\{0,1\}$-matrices.
Conclude that 
$\mathsf{SF} = \mathbb{Z}[h_1,h_2,\ldots]$
where $h_1,h_2,\ldots$ are algebraically independent.
\end{exercise}

\begin{exercise}
Use the Newton identites to show that 
$\mathsf{SF} \otimes_{\mathbb{Z}} \mathbb{Q} \cong \mathbb{Q}[p_1,p_2,\ldots]$
where $p_1,p_2,\ldots$ are algebraically independent.
\end{exercise}

\begin{example}
\[
\begin{pmatrix} e_{11}\\ e_2\\ e_{111}\\ e_{21}\\ e_3\\
e_{1111}\\ e_{211} \\ e_{22}\\ e_{31}\\ e_4
\end{pmatrix}
=
\begin{pmatrix}
2 & 1 &
 & & &
& & & & \\
1 & &
 & & &
& & & & \\
 & &
6 & 3 & 1 &
& & & & \\
 & &
3 & 1 & &
& & & & \\
 & &
1 & & &
& & & & \\
 & &
 & & &
24 & 12 & 6 & 4 & 1 \\
 & &
 & & &
12 & 5 & 2 & 1 & \\
 & &
 & & &
6 & 2 & 1 & & \\
 & &
 & & &
4 & 1 & & & \\
 & &
 & & &
1 & & & &
\end{pmatrix} 
\begin{pmatrix} m_{11}\\ m_2\\ m_{111}\\ m_{21}\\ m_3\\
m_{1111}\\ m_{211} \\ m_{22}\\ m_{31}\\ m_4
\end{pmatrix}
\]
\end{example}

\begin{example}
\[
\begin{pmatrix} h_{11}\\ h_2\\ h_{111}\\ h_{21}\\ h_3\\
h_{1111}\\ h_{211} \\ h_{22}\\ h_{31}\\ h_4
\end{pmatrix}
=
\begin{pmatrix}
2 & 1 &
 & & &
& & & & \\
1 & 1 &
 & & &
& & & & \\
 & &
6 & 3 & 1 &
& & & & \\
 & &
3 & 2 & 1 &
& & & & \\
 & &
1 & 1 & 1 &
& & & & \\
 & &
 & & &
24 & 12 & 6 & 4 & 1 \\
 & &
 & & &
12 & 7 & 4 & 3 & 1 \\
 & &
 & & &
6 & 4 & 3 & 2 & 1 \\
 & &
 & & &
4 & 3 & 2 & 2 & 1 \\
 & &
 & & &
1 & 1 & 1 & 1 & 1
\end{pmatrix} 
\begin{pmatrix} m_{11}\\ m_2\\ m_{111}\\ m_{21}\\ m_3\\
m_{1111}\\ m_{211} \\ m_{22}\\ m_{31}\\ m_4
\end{pmatrix}
\]
\end{example}

\begin{example}
\[
\begin{pmatrix} e_{11}\\ e_2\\ e_{111}\\ e_{21}\\ e_3\\
e_{1111}\\ e_{211} \\ e_{22}\\ e_{31}\\ e_4
\end{pmatrix}
=
\begin{pmatrix}
1 & &
 & & &
& & & & \\
\frac{1}{2} & -\frac{1}{2} &
 & & &
& & & & \\
 & &
1 & & &
& & & & \\
 & &
\frac{1}{2} & -\frac{1}{2} &  &
& & & & \\
 & &
\frac{1}{6} & -\frac{1}{2} & \frac{1}{3} &
& & & & \\
 & &
 & & &
1 & & & & \\
 & &
 & & &
\frac{1}{2} & -\frac{1}{2} & & & \\
 & &
 & & &
\frac{1}{4} & -\frac{1}{2} & \frac{1}{4} & & \\
 & &
 & & &
\frac{1}{6} & -\frac{1}{2} & & \frac{1}{3} & \\
 & &
 & & &
\frac{1}{24} & -\frac{1}{4} & \frac{1}{8} & \frac{1}{3} & -\frac{1}{4}
\end{pmatrix} 
\begin{pmatrix}
p_{11}\\ p_2\\ p_{111}\\ p_{21}\\ p_3\\
p_{1111}\\ p_{211} \\ p_{22}\\ p_{31}\\ p_4
\end{pmatrix}
\]
\end{example}

\subsection{Young Tableaux}

Now we point out a combinatorial interpretation for the Schur functions
and the Kostka numbers.
A \emph{semistandard Young tableau $T$ of shape $\lambda$}
is Young diagram of the partition $\lambda$ whose boxes are filled with
positive integers that are non-strictly increasing in each row
and strictly increasing in each column.
The \emph{type} or \emph{content} $\alpha$ of a semistandard Young tableau
$T$ is the sequence
$(\alpha_1,\alpha_2,\ldots)$ of non-negative integers
where $\alpha_i$ is the number of boxes containing $i$.
Given a semistandard Young tableau $T$ of type $\alpha$,
we have a monomial
\[
x^T = x_1^{\alpha_1}x_2^{\alpha_2} \cdots .
\]

\begin{example}
The following is a Young tableau of shape $422$
and type $(2,3,0,1,2)$:
\begin{center}
\begin{ytableau}
1 & 1 & 2 & 5 \\
2 & 2 \\
4 & 5
\end{ytableau}
\end{center}
The corresponding monomial is $x^T=x_1^2x_2^3x_4x_5^2$.
\end{example}

The following is used as the \emph{definition} of Schur functions in
\cite{Stanley2}; that it agrees with the classical definition
above is \cite[Theorem 7.15.2]{Stanley2}.

\begin{theorem}
If $\lambda$ is a partition, then
\[
s_\lambda = \sum_{T} x^T
\]
where the sum is over all semistandard Young tableaux of shape
$\lambda$.
In particular, $K_{\lambda \mu}$ is the number of semistandard Young
tableaux of shape $\lambda$ and type $\mu$.
\end{theorem}

Various properties of Kostka numbers are easier to check
given this definition:

\begin{exercise}
For partitions $\lambda, \mu$, we have
$K_{\lambda \mu}=0$ unless $\mu \le \lambda$ in the dominance order.
Moreover $K_{\lambda \lambda}=1$.
\end{exercise}

In fact, almost all transition matrices of
$\mathsf{SF}$ can be understood in terms of Kostka numbers
(see \cite[\S{I.6}]{Macdonald} for a comprehensive treatment).
Some notable examples:
\begin{align*}
s_\lambda &= \sum_{\mu} K_{\lambda \mu} m_\mu\\
h_\lambda &= \sum_{\mu} K_{\mu\lambda} s_\mu\\
e_\lambda &= \sum_{\mu} K_{\mu^\dag\lambda} s_\mu.
\end{align*}

For a partition $\lambda \vdash n$, the specific Kostka number
$f^\lambda = K_{\lambda(1)^n}$ is of special interest.
Namely, $f^\lambda$ counts the number of \emph{standard Young tableau}
whose boxes contain each of the integers $\{1,\ldots,n\}$ exactly once
(while still increasing down rows and columns).
For the $(i,j)$th box of a Young diagram, let the \emph{hook length}
$h(i,j)$ count the number of boxes directly below and those directly
to the right of the box $(i,j)$ as well as the box itself.

\begin{theorem}[Hook Length Formula] \label{thm:hook_length}
$f^\lambda = \frac{n!}{\prod h(i,j)}$
where the product is over all boxes of the young diagram of $\lambda$.
\end{theorem}

\begin{example}
Consider the partition $\lambda = (4,3,2)$.
We fill in each box of the Young diagram with its hook length:
\begin{center}
\begin{ytableau}
6 & 5 & 3 & 1 \\
4 & 3 & 1 \\
2 & 1
\end{ytableau}
\end{center}
Thus,
\[
f^\lambda = \frac{9!}{6\cdot 5 \cdot 4 \cdot 3 \cdot 3 \cdot 2}
= 168
\]
in this case.
\end{example}

The change of basis between power sums and Schur functions
are especially interesting for the representation theory of symmetric
groups as we will see shortly.

\begin{example} \label{ex:transSP}
\[
\begin{pmatrix}
p_{11}\\ p_2\\ p_{111}\\ p_{21}\\ p_3\\
p_{1111}\\ p_{211} \\ p_{22}\\ p_{31}\\ p_4
\end{pmatrix}
=
\begin{pmatrix}
1 & 1 &
 & & &
& & & & \\
-1 & 1 &
 & & &
& & & & \\

 & &
1 & 2 & 1 &
& & & & \\
 & &
-1 & 0 & 1 &
& & & & \\
 & &
1 & -1 & 1 &
& & & & \\
 & &
 & & &
1 & 3 & 2 & 3 & 1 \\
 & &
 & & &
-1 & -1 & 0 & 1 & 1 \\
 & &
 & & &
1 & -1 & 2 & -1 & 1 \\
 & &
 & & &
1 & 0 & -1 & 0 & 1 \\
 & &
 & & &
-1 & 1 & 0 & -1 & 1
\end{pmatrix} 
\begin{pmatrix} s_{11}\\ s_2\\ s_{111}\\ s_{21}\\ s_3\\
s_{1111}\\ s_{211} \\ s_{22}\\ s_{31}\\ s_4
\end{pmatrix}
\]
\end{example}

We point out some other useful constructions (without proof)
that hopefully will encourage the reader to
delve more deeply into \cite{Macdonald} and \cite{Stanley2}.

The \emph{Hall inner product} is the unique
symmetric positive definite bilinear form $(-,-)$ on $\mathsf{SF}$
satisfying
\begin{align*}
( s_\lambda, s_\mu ) &= \delta_{\lambda \mu},\\
( h_\lambda, m_\mu ) &= \delta_{\lambda \mu}, \textrm{ and}\\
( p_\lambda, p_\mu ) &= z_\lambda \delta_{\lambda \mu}
\end{align*}
for all partitions $\lambda, \mu$.

A consequence of the Fundamental Theorem is that there is a ring
isomorphism
\[
\omega : \mathsf{SF} \to \mathsf{SF}
\]
given by $\omega(e_\lambda)=h_\lambda$ for every partition $\lambda$.
In view of Proposition~\ref{prop:fund_rel}, we see that
$\omega(h_\lambda)=e_\lambda$ as well.
With a bit more work, one can show that
$\omega(p_\lambda)=\epsilon_\lambda p_\lambda$
and
$\omega(s_\lambda)=s_{\lambda^\dag}$.
This last observation show us that $\omega$ is an isometry
of the Hall inner product:
$( \omega(f), \omega(g) ) = (f, g)$ for
all $f,g \in \mathsf{SF}$.

\section{Representations of Symmetric Groups}

Let $S_n$ be the symmetric group on $n$ letters.
Recall that the conjugacy classes of $S_n$ are in bijection with
partitions of $n$ by taking their cycle types.
Given a partition $\lambda \vdash n$ and a class function
$f \in C(S_n)$, we define $f(\lambda):=f(\sigma)$ where
$\sigma \in S_n$ is any permutation with cycle type $\lambda$.
Let $\chi_\lambda \in C(S_n)$ denote the characteristic function
\[
\chi_\lambda(\sigma) :=
\begin{cases}
1 & \textrm{if $\sigma$ has cycle type $\lambda$,}\\
0 & \textrm{otherwise.}\\
\end{cases}
\]

\begin{theorem}
There is a isometric group isomorphism
\[
\operatorname{ch} : R(S_n) \to \mathsf{SF}^n,
\]
called the \emph{characteristic map}, defined by
\[
\operatorname{ch}(f) :=
\sum_{\lambda \vdash n} \frac{f(\lambda)}{z_\lambda} p_{\lambda}.
\]
Viewed as a class function, the values of $f \in R(S_n)$
can be computed via
\[
f(\lambda) = ( \operatorname{ch}(f), p_\lambda ).
\]
The characteristic functions $\chi_\lambda \in C(S_n)$
correspond to $\frac{p_{\lambda}}{z_\lambda}$ in
$\mathsf{SF}^n_{\mathbb{Q}}$.
The irreducible characters in $R(S_n)$ are
exactly the $\chi^\lambda := \operatorname{chi}(s_\lambda)$
for $\lambda \vdash n$.
The trivial character $\chi^{(n)}$ corresponds to $h_n=s_n$, and
the sign character $\chi^{(1^n)}$ corresponds to $e_n=s_{(1)^n}$.
The involution $\omega : \mathsf{SF}^n \to \mathsf{SF}^n$
corresponds to tensoring with the sign character.
\end{theorem}

\begin{proof}
We only point a few nice facts that are easy to see.
First we define the \emph{characteristic map}
$\operatorname{ch} : C(S_n) \to
\mathsf{SF}^n \otimes_{\mathbb{Z}} \mathbb{C}$
since it's not clear that the image of $R(S_n)$ is even
contained in $\mathsf{SF}^n$.
Recalling that $(p_\lambda,p_\mu)=z_\lambda \delta_{\mu \lambda}$,
the formula
\[
f(\lambda) = ( \operatorname{ch}(f), p_\lambda )
\]
is immediate.  This shows that $\operatorname{ch}$ is bijective
(on complex vector spaces).

The correspondence between
$\chi_\lambda$ and $\frac{p_{\lambda}}{z_\lambda}$
follow now from the observation that
\[
\chi_\lambda(\mu) = \delta_{\lambda \mu} =
\left(\frac{p_{\lambda}}{z_\lambda}, p_\mu\right)
\]
for all $\lambda$ and $\mu$.

Now, recall that the number of elements in $S_n$ with cycle type
$\lambda$ is given by $\frac{n!}{z_\lambda}$.  Thus
\[
(\chi_\lambda, \chi_\mu) =
\begin{cases}
\frac{1}{z_\lambda} & \textrm{if $\lambda=\mu$,}\\
0 & \textrm{otherwise.}\\
\end{cases}
\]
But this is exactly the same as $(p_\lambda,p_\mu)$,
so $\operatorname{ch}$ is an isometry.

We omit the proof of the remaining statements
(see \cite[\S{I.7}]{Macdonald} or \cite[\S{7.18}]{Stanley2}).
\end{proof}

An immediate corollary of the above theorem is that
character table of $S_n$ is precisely the same
as the change of basis matrix between the $\{ p_\lambda \}$
and $\{ s_\lambda \}$ in $\mathsf{SF}_n$.
If the entries of the character table of $S_n$ are denoted
$\chi_\mu^\lambda$, then
\[
\chi_\lambda = \sum_{\mu} \chi_\lambda^\mu \chi^\mu
\]
is equivalent to
\[
p_\lambda = \sum_{\mu} \chi_\lambda^\mu s_\mu .
\]
One can now see that the entries of the matrix from Example~\ref{ex:transSP}
are exactly the entries of the character tables for $S_2$, $S_3$, and
$S_4$.

\begin{definition}
The irreducible representation $V_\lambda$ of $S_n$ corresponding to
$\chi^\lambda$ is the \emph{Specht module} associated to $\lambda$.
\end{definition}

\begin{proposition}
$\displaystyle \dim_{\mathbb{C}} V_\lambda = f^\lambda
=\frac{n!}{\prod h(i,j)}$
\end{proposition}

\begin{proof}
If $f \in R(S_n)$ is the character of $V_\lambda$,
then evaluating at the identity gives
\[
f(e)=f(1^d)= ( \operatorname{ch}(f), p_{(1^d)} )
= (s_\lambda, h_{(1^d)}) = K_{\lambda(1)^f}=f^\lambda.
\]
Now we appeal to Theorem~\ref{thm:hook_length}.
\end{proof}

Defining the graded group
\[
R(S_\ast) := \bigoplus_{n \ge 0} R(S_n)
\]
we obtain a characteristic map
\[
\operatorname{ch} : R(S_\ast) \to \mathsf{SF}
\]
by adding together graded components.
However, the existing multiplication on each $R(S_n)$
\emph{does not} correspond to the multiplication on $\mathsf{SF}$.
We define a multiplication on $R(S_\ast)$ that makes
$\operatorname{ch}$ into a graded ring isomorphism.

There is a natural embedding $S_n \times S_m \hookrightarrow S_{n+m}$;
there are many ways of doing this, but they are all conjugate.
Given a representation $\rho$ of $S_n$, we obtain a representation
$\widetilde{\rho}$ of $S_n \times S_m$ from $\rho$ by precomposition
with the first projection.  Similarly, given a representation $\sigma$
of $S_m$, we obtain a representation $\widetilde{\sigma}$ of
$S_n \times S_m$.

Let $R(S_n)$ be the representation ring of the symmetric group $S_n$. 
We define a bilinear multiplication
\[ \boxtimes : R(S_n) \times R(S_m) \to R(S_{n+m}) \]
via
\[
\rho \boxtimes \sigma := \operatorname{Ind}_{S_n \times S_m}^{S_{n+m}}
(\widetilde{\rho} \otimes \widetilde{\sigma}).
\]
This turns $R(S_\ast)$ into a commutative, graded ring
and $\operatorname{ch}$ is a graded ring isomorphism.

\subsection{Explicit Description of Specht modules}

Specht modules can also be described without
reference to symmetric functions
(see \cite[\S{4}]{FultonHarris} and \cite[\S{5.11-17}]{Etingof}).

Here we actually construct each Specht module $V_\lambda$
as a subrepresentation of the regular representation of $S_n$.
Note that the isotypic component associated to $V_\lambda$ usually has
multiplicity greater than $1$, so the construction unsurprisingly relies
on an arbitrary choice.

\begin{definition}
A \emph{Young tableau} $T$ is a Young diagram for a partition $\lambda$
of $n$ where each number in $\{1,\ldots,n\}$ is assigned to exactly one
box.  (Note that this neither a special case nor a generalization
of the standard and semistandard Young tableau discussed above.)
Given a Young tableau $T$, we define $P_T$ as the
subgroup of $S_n$ that permutes only the numbers within each row of $T$
and $Q_T$ as the subgroup that permutes only the numbers within each
column of $T$.  
\end{definition}

\begin{example}
The following is a Young tableau for the partition $322$:
\begin{center}
\begin{ytableau}
3 & 1 & 5 \\
6 & 2 \\
4 & 7
\end{ytableau}
\end{center}
We have
\[
P_T = S_{\{1,3,5\}} \times S_{\{2,6\}} \times S_{\{4,7\}}
\textrm{ and }
Q_T = S_{\{3,4,6\}} \times S_{\{1,2,7\}}
\]
where $S_X$ is the group of permutations of the set $X$. 
\end{example}

If $\lambda = (\lambda_1,\ldots,\lambda_r)$ is a partition,
define $S_\lambda := S_{\lambda_1} \times \cdots \times S_{\lambda_r}$.
Observe that $P_T \cong S_\lambda$
and $Q_T \cong S_{\lambda^\dag}$.
The subgroups $P_T$ and $Q_T$ depend on the choice of tableau $T$, but
the conjugacy class only depends on the corresponding partition
$\lambda$.

Given a Young tableau $T$ and a representation $W$ of $S_n$,
define the \emph{Young projectors}:
\[
a_T := \frac{1}{|P_T|}\sum_{\sigma \in P_T} \sigma
\textrm{ and }
b_T := \frac{1}{|Q_T|}\sum_{\sigma \in Q_T} \epsilon(\sigma)\sigma
\]
which are easily seen to be projections in $\operatorname{End}(W)$.
The \emph{Young symmetrizer} is the endomorphism $c_T = a_T \circ b_T$.
One checks that $c_T = b_T \circ a_T$.

\begin{theorem}
Suppose $\lambda$ is a partition of $n$.
If $V_{reg}$ is the regular representation and $T$ is a Young tableau
for $\lambda$, then the image of $c_T(V_{reg})$ is isomorphic to the
Specht module $V_\lambda$.
\end{theorem}

\begin{proof}
We only sketch this.
First, let $U_T = a_T(V_{reg})$ and $W_T = b_T(V_{reg})$.
We observe that
\[
U_T \cong \operatorname{Ind}_{P_T}^{S_n} 1_{P_T}
\]
and
\[
W_T \cong \operatorname{Ind}_{Q_T}^{S_n} \epsilon_{Q_T}
\]
where $1_{P_T}$ is the trivial representation and $\epsilon_{Q_T}$ is the sign
representation.
In other words, the characteristic of $U_T$ is
\[
\operatorname{ch}(1 \boxtimes \cdots \boxtimes 1)
= h_{\lambda_1} \cdots h_{\lambda_r} = h_\lambda,
\]
while the characteristic of $W_T$ is
\[
\operatorname{ch}(\epsilon \boxtimes \cdots \boxtimes \epsilon)
= e_{\lambda^\dag_1} \cdots e_{\lambda^\dag_r} = e_{\lambda^\dag}.
\]
Writing out $h_\lambda$ and $e_{\lambda^\dag}$ in the Schur basis,
we see that $s_\lambda$ is the only basis vector with a non-zero entry
in both.
Moreover, $(s_\lambda,h_\lambda)=(s_\lambda,e_{\lambda^\dag})=1$.
Thus, the image $c_T = a_T \circ b_T$ is isomorphic to the Specht module
$V_\lambda$ provided the image is non-zero.

Let $\{ v_\sigma \}_{\sigma \in S_n}$ be the standard basis for the regular
representation $V_{reg}$.
We have the concrete description
\[
c_T(v_{1})  = \frac{1}{|P_T| |Q_T|}\sum_{\sigma \in P_T}\sum_{\tau \in Q_T}
\epsilon(\tau) v_{\sigma\tau} .
\]
Since $P_T \cap Q_T = \{1\}$, the $v_{\sigma\tau}$ are all distinct.
Thus $c_T \ne 0$ as desired.
\end{proof}

\section{Representations of $\operatorname{GL}(V)$}

Schur functors are described directly in
\cite[\S{6}]{FultonHarris} and \cite[\S{5.19,5.20-23}]{Etingof}.
Slightly more sophisticated expositions can be found in
\cite[Appendix 7.2]{Stanley2} and \cite[Appendix I.A]{Macdonald}.

\begin{definition}
Given a complex $n$-dimensional vector space $V$,
a \emph{polynomial representation} (resp. \emph{rational represenation} of
$\operatorname{GL}(V)$ is a representation
\[
\rho : \operatorname{GL}(V) \to \operatorname{GL}_N(\mathbb{C})
\]
where the entries of $\rho(g)$ are polynomial (resp. rational)
functions of the entries of $g$.
\end{definition}

\begin{remark}
For those who know some algebraic geometry,
the rational representations are rational maps on the ambient matrix
ring $\mathbb{C}^{n^2}$, but they are regular on the open set
$\operatorname{GL}_n(\mathbb{C})$.
The polynomial representations are regular on the whole of
$\mathbb{C}^{n^2}$.
Watch out: some authors use ``polynomial representation'' synonymously with
rational representations.
\end{remark}

\begin{example}
If $V = \mathbb{C}^2$, then $\mathcal{S}^2(V) \cong \mathbb{C}^3$
has a natural action of $\operatorname{GL}(V)$.
Indeed, choosing bases $\{x,y\}$ for $V$ and $\{x^2,xy,y^2\}$
for $\mathcal{S}^2(V)$ we obtain a representation
$\rho : \operatorname{GL}_2(k) \to \operatorname{GL}_3(k)$
with
\[
\rho
\begin{pmatrix} a & b \\ c & d \end{pmatrix}
=
\begin{pmatrix}
a^2 & 2ab & b^2\\
ac & ad+bc & bd\\
c^2 & 2cd & d^2
\end{pmatrix} 
\]
as explicit description.
\end{example}

\begin{example}
If $V$ has dimension $n$, recall that $\Lambda^n(V)$ has dimension $1$.
The natural representation
$\rho: \operatorname{GL}(V) \to \operatorname{GL}(\Lambda^n(V)) \cong k$
is the determinant.
\end{example}

More generally, $\mathcal{S}^k(V)$ and $\Lambda^k(V)$
have canonical actions of $\operatorname{GL}(V)$ for all $k \ge 0$.

\begin{example}
Consider the representation
$\rho : \operatorname{GL}_1(\mathbb{C}) \to
\operatorname{GL}_1(\mathbb{C})$
given by
\[
\rho(z) = \frac{z}{|z|} .
\]
This is neither a polynomial nor rational representation.
\end{example}

\begin{example}
The \emph{dual representation} $V^\vee$ of $V$ is the natural
action of $\operatorname{GL}(V)$ on $V^\vee$.
Choosing a basis and taking its dual basis,
the dual representation corresponds to taking the transpose inverse
$(A^T)^{-1}$
of a matrix $A$.
This is not a polynomial representation since the entries of $(A^T)^{-1}$ have
denominators.
However, recall that the inverse matrix $A^{-1}$ has the form
$\det(A)\operatorname{adj}(A)$ where
$\operatorname{adj}(A)$ is the \emph{adjugate matrix}.
The entries of the adjugate matrix are polynomial functions of the
entries of the original matrix.
Since $(A^T)^{-1}=\operatorname{adj}(A)^T \det(A)^{-1}$,
we conclude that $V^\vee$ is a rational representation.
\end{example}

The difference between polynomial and rational representations is,
fortunately, easily characterized.  Indeed, the denominators that occur
in the rational functions can only be powers of the determinant or else
the representation is not defined for every point of
$\operatorname{GL}(V)$.

\begin{proposition}
If $\rho$ is a rational representation of $\operatorname{GL}(V)$,
then there is a unique minimal non-negative integer $m$
and a unique polynomial representation $\sigma$
such that
such that
\[
\rho(g) = \frac{\sigma(g)}{\det(g)^m}
\]
for all $g \in \operatorname{GL}(V)$. 
\end{proposition}

Given a complex $n$-dimensional vector space $V$,
recall that there is a natural action of $S_d$ on the tensor power
$V^{\otimes d}$ satisfying
\[
\sigma(v_1 \otimes \cdots \otimes v_d) =
\sigma(v_{\sigma^{-1}(1)} \otimes \cdots \otimes v_{\sigma^{-1}(d)})
\]
for $\sigma \in S_d$.
There is also a natural ``diagonal'' action of $\operatorname{GL}_n(V)$
on $V^{\otimes d}$ satisfying
\[
g(v_1 \otimes \cdots \otimes v_d) = g(v_1) \otimes \cdots \otimes g(v_d)
\]
for all $g \in \operatorname{GL}(V)$.
These actions clearly commute, so we obtain an action of
$S_d \times \operatorname{GL}(V)$ on $V^{\otimes d}$.

\begin{definition}
Given a partition $\lambda \vdash d$, we
have the \emph{Schur functor} $\mathbb{S}_\lambda$,
which takes a vector space $W$ to the following
$\operatorname{GL}(W)$-representation:
\[
\mathbb{S}_\lambda(W) :=
\operatorname{Hom}^{S_d}_{\mathbb{C}}(V_\lambda,W^{\otimes d}) \ .
\]
\end{definition}

\begin{remark}
For those who know some category theory,
each Schur functor $\mathbb{S}_\lambda$ is a covariant functor
from the category of finite-dimensional vector spaces to itself.
This implies that if $f : W \to U$ is a linear map,
then we also have a linear map
\[
\mathbb{S}_\lambda(f) : \mathbb{S}_\lambda(W) \to \mathbb{S}_\lambda(U).
\]
The fact that these are $\operatorname{GL}(W)$ representations can be
seen as just a consequence of the fact that they are functors.
(In particular, Schur functors can be defined for more general
tensor categories.)
\end{remark}

\begin{theorem}[Schur-Weyl]
Let $W$ be an $n$-dimensional complex vector space
and let $d \ge 0$.
As an $S_d \times \operatorname{GL}(W)$-representation, there is a
canonical decomposition
\[
W^{\otimes d} =
\bigoplus_{\substack{\lambda \vdash d\\ \ell(\lambda) \le n}}
V_\lambda \otimes \mathbb{S}_\lambda(W)
\]
where $V_\lambda$ is the Specht module of $\lambda$ and each
\[
\mathbb{S}_\lambda(W) :=
\operatorname{Hom}^{S_d}_{\mathbb{C}}(V_\lambda,W^{\otimes d})
\]
is an irreducible $\operatorname{GL}(W)$-representation.
\end{theorem}

\begin{theorem}
The isomorphism classes of all \emph{polynomial}
irreducible representations
of $\operatorname{GL}(W)$ are precisely the $\mathbb{S}_\lambda(W)$
where $\ell(\lambda) \le d$.
Moreover, if $g \in \operatorname{GL}(W)$ has eigenvalues
$\alpha_1,\ldots, \alpha_n$, then
\[
\operatorname{tr}(\mathbb{S}_\lambda(g)) = s_\lambda(\alpha_1,\alpha_2,\cdots,
\alpha_n,0,0,\cdots)
\]
we conclude $s_\lambda$ is the character of $\mathbb{S}_\lambda$.
\end{theorem}

By evaluating $\mathbb{S}_\lambda$ at the identity, we can determine the
dimensions of the irreducible representations obtained from Schur
functors.

\begin{corollary}[Weyl Dimension Formula]
If $W$ is an $n$-dimensional vector space and $\lambda$ is a partition.
If $\ell(\lambda) \le n$, then
\[
\dim\ \mathbb{S}_\lambda(W) = s_\lambda(1,1,\ldots,1,0,\ldots)
= \prod_{1 \le i < j \le n} \frac{\lambda_i-\lambda_j +  j - i}{j-i}.
\]
If $\ell(\lambda) > n$, then $\dim\ \mathbb{S}_\lambda(W) = 0$.
\end{corollary}

\begin{example}
Since $V_{(d)}$ is the trivial $S_d$-representation,
we see that
\[
\mathbb{S}_{(d)}(W) = \operatorname{Hom}^{S_d}_{\mathbb{C}}(\mathbb{C},W^{\otimes d})
\cong \operatorname{Sym}^d(W) \cong \mathcal{S}^d(W) .
\]
\end{example}

\begin{example}
Since $V_{(1^d)}$ is the sign $S_d$-representation $\epsilon$,
we see that
\[
\mathbb{S}_{(1^d)}(W)L = \operatorname{Hom}^{S_d}_{\mathbb{C}}(\epsilon,W^{\otimes d})
\cong \operatorname{Alt}^d(W) \cong \Lambda^d(W) .
\]
Note that $\mathbb{S}_{(1^d)}(W)=0$ when $\dim(W) > d$.
\end{example}

\bibliographystyle{alpha}
\bibliography{rep_theory}

\end{document}


