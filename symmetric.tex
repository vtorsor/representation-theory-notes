\documentclass[12pt]{article}

\usepackage{amssymb,amsmath,amsthm}
\usepackage{ytableau}

% theorem styles (I like everything to have the same counter)
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{exercise}[theorem]{Exercise}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% some numbering settings
\numberwithin{equation}{section}

\usepackage{fancyhdr}
\usepackage{lastpage}
\setlength{\headheight}{15.2pt}
\renewcommand{\footrulewidth}{0.4pt}% default is 0pt
\setlength{\footskip}{30pt}
\pagestyle{fancy}

\makeatletter
\let\ps@plain\ps@fancy 
\makeatother

\lhead{MATH 742}
\chead{$S_n$ and $\operatorname{GL}_n$}
\rhead{Spring 2023}
\lfoot{Last Revised: \today}
\cfoot{}
\rfoot{\thepage\ of \pageref{LastPage} }

\begin{document}

%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
\title{Symmetric Groups and General Linear Groups}
\author{Alexander Duncan}

\maketitle

Much of this material is drawn from
\cite[\S{4,6,A}]{FultonHarris},
\cite[\S{5.12--5.19}]{Etingof},
\cite[\S{I}]{Macdonald}, and
\cite[\S{7}]{Stanley2}.

%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%

\section{Partitions}

Recall that a \emph{partition} $\lambda$ is a sequence of decreasing
non-negative integers
$\lambda_1 \ge \lambda_2 \ge \cdots$ that is eventually $0$.
Some standard terminology:
\begin{itemize}
\item The non-zero $\lambda_i$ are the \emph{parts} of $\lambda$.
\item The number $\ell(\lambda)$ of parts is the \emph{length} of $\lambda$.
\item The sum $|\lambda|=\sum_{i \ge 0} \lambda_i$ is the \emph{weight} of $\lambda$.
\item A ``partition of $n$'' is a partition of weight $n$.
\item $\lambda \vdash n$ means $\lambda$ is a partition of $n$.
\item The number $m_i(\lambda)$ of parts equal to $i$ is
the \emph{multiplicity} of $i$ in $\lambda$.
\item Partitions can be written $\lambda_1 + \lambda_2 + \cdots + \lambda_r$.
\item We may use the shorthand $\lambda = (1^{m_1} 2^{m_2} \cdots r^{m_r})$.
\item $\lambda+\mu$ is the partition $(\lambda_1+\mu_1, \ldots)$.
\item $\lambda \subseteq \mu$ means $\lambda_i \le \mu_i$ for all $i \ge 1$.
\end{itemize}

Partitions are often drawn as \emph{Young tableaux}.  This is just a
series of empty boxes where each row contains $\lambda_i$ boxes.
There are some differing conventions between different areas of math, so
read any source carefully.

Given a partition $\lambda$, the \emph{conjugate partition}
is the partition $\lambda'$ obtained by reflecting the Young diagram in
the downwards-right diagonal line.  More explicitly,
$\lambda'_i$ is the number of parts such that $\lambda_j \ge i$. 

\begin{example}
The partitions of $4$ are as follows:
\begin{center}
\begin{tabular}{ccccc}
4 & 3+1 & 2+2 & 2+1+1 & 1+1+1+1 \\
\ydiagram{4} & \ydiagram{3,1} & \ydiagram{2,2} & \ydiagram{2,1,1} &
\ydiagram{1,1,1,1}
\end{tabular}
\end{center}
\end{example}

\begin{example}
Let $\lambda = (4,4,2,2,2,1)$.
We may also write $\lambda$ as $4+4+2+2+2+1$ or $1^12^34^2$.
We have parts $\lambda_1=4$, $\lambda_2=4$,
$\lambda_3=2$,
$\lambda_4=2$,
$\lambda_5=2$, and
$\lambda_6=1$.
We have length $\ell(\lambda)=6$, weight $|\lambda|=15$,
and multiplicities $m_1(\lambda)=1$, $m_2(\lambda)=3$,
$m_3(\lambda)=0$, and $m_4(\lambda)=2$.
The Young tableau is
\begin{center}
\ydiagram{4,4,2,2,2,1}.
\end{center}
The conjugate partition $\lambda'$ is $(6,5,2,2)$.
\end{example}

We use the notation $\operatorname{Par}(n)$ to denote the set of
partitions of $n$.  And the notation $\operatorname{Par}$ for the set of
all partitions of all weights.

Recall that every permutation $\sigma \in S_n$ can be written as a
product of disjoint cycles, which is unique up to reordering of
the cycles.  Counting the cycles of length $1$, we see that the orders
of the constituent cycles give a partition $\lambda \vdash n$.
For example $(1\ 4\ 3)(2\ 8)(6\ 7) \in S_9$ has cycle type
$3+2+2+1+1$.
The following is standard in most group theory texts:

\begin{proposition}
Two permutations in $S_n$ are conjugate if and only if they have the
same cycle type.
In particular, the conjugacy classes of $S_n$ are in canonical bijective
correspondence with $\operatorname{Par}(n)$.
\end{proposition}

For every partition $\lambda$, we define the following integer
\[
z_\lambda = \prod_{i \ge 1} i^{m_i} m_i!
\]
where $m_i=m_i(\lambda)$ denotes the multiplicities.

\begin{exercise}
Prove that, if $\sigma \in S_n$ has cycle type $\lambda$,
then the centralizer $Z_{S_n}(\sigma)$ has order $z_\lambda$.
Equivalently, the number of elements of $S_n$ with cycle type $\lambda$
is $n!/z_\lambda$.
\end{exercise}

\section{Symmetric Polynomials}

There is a natural left action of the symmetric group $S_n$ on the ring of
polynomials $R=\mathbb{Z}[x_1,\ldots,x_n]$ by permuting the variables.
More precisely, there is a unique ring automorphism of $R$ defined
by $x_i \mapsto x_{\sigma(i)}$ for each variable $x_i$ and each
permutation $\sigma \in S_n$.
Alternatively, if $\sigma \in S_n$, the we have
\[
(\sigma \cdot f)(a_1,\ldots,a_n) =
f\left(a_{\sigma(1)}, \ldots, a_{\sigma}(n)\right)
\]
for $f \in R$ and $a_1,\ldots,a_n \in \mathbb{Z}$.

\begin{definition}
A polynomial $f \in \mathbb{Z}[x_1,\ldots, x_n]$ is \emph{symmetric}
if $\sigma \cdot f = f$ for all $\sigma \in \Sigma$.
We denote by $\mathsf{SF}_n$ the set of symmetric polynomials
$\mathbb{Z}[x_1,\ldots,x_n]^{S_n}$ in $n$ variables.
\end{definition}

The set $\mathsf{SF}_n$ forms a graded ring
\[
\mathsf{SF}_n = \bigoplus_{d \ge 0} \mathsf{SF}_n^d
\]
where each $\mathsf{SF}_n^d = \mathbb{Z}[x_1,\ldots,x_n]_{(d)}^{S_n}$
is the subgroup of homogeneous symmetric polynomials of degree $d$.

Given a tuple $\alpha = (\alpha_1,\ldots,\alpha_n) \in \mathbb{N}^n$
we use the shorthand
\[
x^\alpha = x_1^{\alpha_1} \cdots x_n^{\alpha_n}
\]
to denote monomials in $\mathbb{Z}[x_1,\ldots,x_n]$.

Given a partition $\lambda \vdash d$ with length $\ell(\lambda) \le n$,
the \emph{monomial symmetric polynomial associated to $\lambda$}
is given by
\[
m_\lambda := \sum_{\alpha} x^\alpha
\]
where $(\alpha_1,\ldots,\alpha_n)$ ranges over all
\emph{distinct} permutations of $(\lambda_1,\ldots,\lambda_n)$.

\begin{exercise}
Prove that $\displaystyle z_\lambda m_\lambda = \sum_{\sigma \in S_n}
x^{\sigma(\lambda)}$ for all $\lambda$ of length $\ell(\lambda) \le n$.
\end{exercise}

\begin{example}
If $n=3$, then we have
\begin{align*}
m_\emptyset &= 1\\
m_1 &= x_1 + x_2 + x_3\\
m_2 &= x_1^2 + x_2^2 + x_3^2\\
m_{11} &= x_1x_2 + x_1x_3 + x_2x_3\\
m_{111} &= x_1x_2x_3 \\
m_{14} &= x_1x_2^4 + x_1^4x_2 + x_1x_3^4 + x_1^4x_3 + x_2x_3^4 +
x_2^4x_3.
\end{align*}
\end{example}

Importantly, we have the following:

\begin{proposition}
Monomial symmetric polynomials form a basis for $\mathsf{SF}_n$.
Specifically,
\[
\mathsf{SF}_n^d = \operatorname{span}_{\mathbb{Z}}
\{ m_\lambda \mid \lambda \vdash d, \ell(\lambda) \le n \}.
\]
\end{proposition}

\begin{proof}
The partitions of length at most $n$ are a system of distinct
representatives for the $S_n$-orbits of $\mathbb{N}^n$.
The monomials in $m_\lambda$ are precisely those of these orbit of
$\lambda$.
The coefficient of every monomial
in $m_\lambda$ is either $0$ or $1$ and every possible monomial
occurs in exactly one $m_\lambda$.
If $f$ is a symmetric polynomial, then the coefficient
of a monomial $x^\alpha$ must be the same as $x^{\sigma(\alpha)}$
for every $\sigma \in S_n$.  
\end{proof}

There are several notable additional families of symmetric polynomials
which we define now.

\begin{definition}
For positive integers $d$, we define
the \emph{elementary symmetric polynomial $e_d$ of degree $d$} as
\[
e_d = m_{1^d} = \sum_{1 \le i_1 < i_2 < \cdots < i_d \le n} x_{i_1}x_{i_2}\cdots
x_{i_d},
\]
the \emph{complete homogeneous symmetric polynomial $h_d$ of degree $d$} as
\[
h_d = \sum_{\lambda \vdash d} m_\lambda = \sum_{1 \le i_1 \le i_2 \le \cdots \le i_d \le n} x_{i_1}x_{i_2}\cdots
x_{i_d},
\]
and the \emph{power sum symmetric polynomial $p_d$ of degree $d$} as
\[
p_d = m_d = \sum_{1 \le i \le n} x_i^d.
\]
By convention, $e_0=h_0=p_0=1$.
\end{definition}

\begin{remark}
The conventions for $e_0$ and $h_0$ are uncontroversial,
but many references leave $p_0$ undefined.
Indeed, there are good reasons to instead define $p_0=n$, but this does not
extend to the ring of symmetric functions discussed below. 
\end{remark}

\begin{example}
If $n=3$, then we have
\begin{align*}
e_1 = h_1 = p_1 &= x_1 + x_2 + x_3\\
e_2 &= x_1x_2 + x_1x_3 + x_2x_3\\
e_3 &= x_1x_2x_3 \\
e_4 &= 0 \\
h_2 &= x_1^2 + x_2^2 + x_3^2 + x_1x_2 + x_1x_3 + x_2x_3\\
h_3 &= x_1^3 + \cdots + x_1^2x_2 + \cdots + x_1x_2x_3\\
p_2 &= x_1^2 + x_2^2 + x_3^2\\
p_3 &= x_1^3 + x_2^3 + x_3^3
\end{align*}
\end{example}

It is worth mentioning right away (but whose proof we will defer)
some fundamental results.  First, we have \emph{Newton's identities}:
\[
de_d = \sum_{i=1}^d (-1)^{i-1} p_i e_{d-i} ,
\]
and the fundamental relation
\[
0 = \sum_{i=0}^d (-1)^i e_i h_{d-i},
\]
which hold for all positive integers $d$.
These allow one to recursively compute $p_i$'s and $h_i$'s in terms
of $e_i$'s (and vice versa).

We also have the \emph{Fundamental Theorem of Symmetric
Polynomials} which states that $e_1,\ldots,e_n$ are algebraically independent
generators of the ring $\mathsf{SF}_n$.
In fact, combining this with the above relations, we have
\begin{align*}
\mathbb{Z}[x_1,\ldots,x_n]^{S_n} &= \mathbb{Z}[e_1,\ldots,e_n]\\
\mathbb{Z}[x_1,\ldots,x_n]^{S_n} &= \mathbb{Z}[h_1,\ldots,h_n]\\
\mathbb{Q}[x_1,\ldots,x_n]^{S_n} &= \mathbb{Q}[p_1,\ldots,p_n]
\end{align*}
where rational coefficients are necessary for the last equality.
The proofs of these equalities are not very hard, but we defer them for
the moment as they are consequences of more general facts.

\subsection{Alternating and Schur Polynomials}

Let $\epsilon : S_n \to \{\pm 1\}$ be the sign homomorphism
and let $A_n = \ker(\epsilon)$ be the alternating group on $n$ letters.

\begin{definition}
A polynomial $f \in \mathbb{Z}[x_1,\ldots,x_n]$ is \emph{alternating} if
$\sigma \cdot f = \epsilon(\sigma)f$ for all $\sigma \in S_n$.
Given an element $\alpha \in \mathbb{N}^n$, define
\[
a_\alpha = \sum_{\sigma \in S_n} \epsilon(\sigma) x^{\sigma(\alpha)},
\]
which is an alternating polynomial.
\end{definition}

Note that $a_\alpha=0$ if and only if the entries of $\alpha$ are
not distinct.  We also see that every alternating polynomial is a linear
combination of $a_\lambda$'s for partitions $\lambda$ where the parts
$\lambda_i$ are all distinct.
Observe that all parts of $\lambda$ are distinct if and only if
$\delta \subseteq \lambda$ where
$\delta=(n-1,n-2,\ldots,1,0)$.
We have the following:

\begin{lemma}
The set
\[
\{ a_\lambda \mid \ell(\lambda) \le n, \delta \subseteq \lambda \}
\]
is a basis for the group of alternating polynomials.
\end{lemma}

\begin{example}
The \emph{Vandermonde polynomial} $\Delta \in \mathbb{Z}[x_1,\ldots,x_n]$
is defined via
\[
\Delta = \prod_{1 \le i < j \le n} (x_i-x_j).
\]
Note that $(i\ j) \cdot \Delta = -\Delta$ for all $i \ne j$.
We conclude that $\sigma(\Delta) = \epsilon(\Delta)$
for all $\sigma \in S_n$.
Thus $\Delta$ is alternating.
Observe that $\Delta=a_\delta$.
\end{example}

\begin{lemma}
Every alternating polynomial $f$ has the form $g \Delta$
where $g$ is a symmetric polynomial. 
\end{lemma}

\begin{proof}
It suffices to show that $(x_i-x_j)$ divides $f$ for all $i \ne j$.
Indeed, suppose $c_\alpha x^\alpha$ is a monomial in $f$
and write $x^\alpha = x_i^u x_j^v x^\beta$ where $x_i$ and $x_j$
do not divide $x^\beta$.
Since $f$ is alternating, $-c_\alpha x_i^v x_j^u x^\beta$
also must appear in $f$.
Thus $c_\alpha (x_i^u x_j^v - x_i^v x_j^u) x^\beta$ occurs in $f$.
Each of these divisible by $(x_i-x_j)$ as desired.
\end{proof}

The following definition now makes sense:

\begin{definition}
For a partition $\lambda$ of length $\le n$, the \emph{Schur polynomial}
is the symmetric polynomial
$s_\lambda = a_{\lambda+\delta}/a_\delta$.
\end{definition}

Moreover, we have the following:

\begin{proposition}
The set of Schur polynomials
\[
\{ s_\lambda \mid \lambda \vdash d, \ell(\lambda) \le n \}
\]
are a basis for $\mathsf{SF}^d_n$.
\end{proposition}

The \emph{Kostka numbers} $K_{\lambda \mu}$ are the entries of the
change of basis matrix between the monomial basis and the Schur basis.
Specifically, they are non-negative integers such that
\[
s_\lambda = \sum_{\mu\, \vdash |\lambda|} K_{\lambda \mu} m_\mu
\]
for all partitions $\lambda,\mu$.

\begin{exercise}
Prove that $s_{(d)} = h_d$ and $s_{(1^d)} = e_d$.
\end{exercise}

\begin{theorem}[Fundamental Theorem of Alternating Polynomials]
The ring $\mathbb{Z}[x_1,\ldots,x_n]^{A_n}$ is a free
$\mathsf{SF}_n$-module with basis $\{1, \Delta\}$.
In other words, every $A_n$-invariant polynomial $f$ can be written uniquely
as $f=p+\Delta q$ where $p,q$ are symmetric.
\end{theorem}

\begin{remark}
If $V$ is an $n$-dimensional complex linear representation of $G$,
then we have a natural action of $G$ on the polynomial ring
$S=\mathbb{C}[x_1,\ldots,x_n]$ by viewing it as the symmetric algebra
$\mathcal{S}(V^\vee)$.
A famous theorem of Hochster-Roberts proves that the invariant ring
$S^G=\mathbb{C}[x_1,\ldots,x_n]^G$ is a Cohen-Macaulay ring:
there exists a polynomial subring $R=\mathbb{C}[f_1,\ldots,f_n]$
such that $S^G$ is a free $R$-module.
The ``Fundamental Theorem of Alternating Polynomials'' can be seen as a
very special case of this fact (where the subring and basis have
particular interpretations).
\end{remark}

\subsection{Symmetric and Exterior Powers}

We now see some of the connections of symmetric functions and
representation theory:

\begin{proposition}
Suppose $V$ is an $n$-dimensional vector space and
$\varphi \in \operatorname{End}(V)$ has eigenvalues
$\lambda_1,\ldots,\lambda_n$.
Then the natural action of $\varphi$ on the exterior power $\Lambda^d V$
has trace
\[
\operatorname{tr}\left( \Lambda^d \varphi \right)
= e_d(\lambda_1,\ldots,\lambda_n)
\]
and the natural action of $\varphi$ on the symmetric power
$\mathcal{S}^d V$ has trace
\[
\operatorname{tr}\left( \mathcal{S}^d \varphi \right)
= h_d(\lambda_1,\ldots,\lambda_n).
\]
\end{proposition}

\begin{proof}
It suffices to work over an algebraically closed field $k$.
We prove the statement for $\Lambda^d V$ since the argument for
$\mathcal{S}^d$ is very similar. 

First, we assume that $\varphi$ is diagonalizable with eigenvectors
$v_1,\ldots, v_n$ corresponding to eigenvalues
$\lambda_1,\ldots,\lambda_n$.
Now, an eigenbasis for $\Lambda^d V$ is given by
\[
\{ v_{i_1}\wedge v_{i_2}\wedge \cdots \wedge v_{i_d} \mid
1 \le i_1 < i_2 < \cdots < i_d \le n \} \ .
\]
The corresponding eigenvalues of $\Lambda^d \varphi$ are therefore
\[
\{ \lambda_{i_1} \lambda_{i_2} \cdots \lambda_{i_d} \mid
1 \le i_1 < i_2 < \cdots < i_d \le n \} \ .
\]
The trace of $\Lambda^d \phi$ is just the sum of the eigenvalues, which
is $e_d(\lambda_1,\ldots,\lambda_n)$ as desired.

Now we consider the case where $\varphi$ is not diagonalizable.
In this case $\varphi$ has a Jordan canonical form.  Thus,
we have a basis $v_1,\ldots, v_n$ for $V$ such that $\varphi$ is
represented by $D+N$ where $D$ is a diagonal matrix and
$N$ is a lower triangular matrix.
Observe that $N(v_i)$ is a linear combination of $v_{i+1},\ldots, v_n$.

Define a total ordering on $\mathbb{N}^n$ where
$(a_1,\ldots,a_n) < (b_1,\ldots,b_n)$ if $a_i < b_i$ for the minimal $i$
on which $a_i \ne b_i$.
We now observe that
\[
(D+N)(v_{i_1}\wedge \cdots \wedge v_{i_d})
= D(v_{i_1}\wedge \cdots \wedge v_{i_d})
+ \textrm{higher terms} 
\]
where the ``higher terms'' are scalar multiples of
$v_{j_1}\wedge \cdots \wedge v_{j_d}$
where $(j_1,\ldots,j_d) > (i_1,\ldots,i_d)$.
Thus, appropriately ordered, our basis for $\Lambda^d V$
also represents $\Lambda^d V$ as a lower-triangular matrix.
The trace only depends on the diagonal entries so the result follows
from the diagonalizable case.
\end{proof}

Another way of understanding the previous proposition is that
$\Lambda^d V$ and $\mathcal{S}^d V$ are representations of
$\operatorname{GL}(V)$ with corresponding characters $e_d$ and
$h_d$, respectively.
We will see that there is a class of symmetric polynomials
called \emph{Schur polynomials} which are precisely the characters
of the irreducible \emph{polynomial} representations of
$\operatorname{GL}(V)$.


\section{The Ring of Symmetric Functions}

Many of the relations between various special symmetric polynomials are
basically independent of the number $n$ of variables $x_1,\ldots,x_n$
in the ambient polynomial ring.  The \emph{ring of symmetric functions}
is a standard object in algebraic combinatorics that facilitates
this.  Several equivalent constructions exist, but we will follow
the construction from \cite{Stanley2}, which is fairly ``down to earth.''

Let $\mathbb{Z}[[\{x_n\}_{n \in \mathbb{N}_{>0}}]]$ be the ring of formal
power series in countably many variables.  Recall that this means that
we allow only finitely many $x_i$ in each monomial, but each element may be
a linear combination of infinitely many monomials and there may be no upper
bound on the subscripts $i$ occurring among the $x_i$'s in each
monomial.
For a non-negative integer $d$, the subgroup
$\mathbb{Z}[[\{x_n\}_{n \in \mathbb{N}_{>0}}]]_{(d)}$ consists of those
elements whose monomials all have degree exactly $d$ (in other words,
exactly $d$ variables $x_i$ in each monomial, counting multiplicities).

Let $S_{\mathbb{N}_{>0}}$ be the symmetric group on $\mathbb{N}_{>0}$; in other
words, the group of all bijections $\mathbb{N}_{>0} \to \mathbb{N}_{>0}$.
There is a natural action of $S_{\mathbb{N}_{>0}}$ on
$\mathbb{Z}[[\{x_n\}_{n \in \mathbb{N}_{>0}}]]$ by permuting variables that
preserves the degree.
A \emph{homogeneous symmetric function of degree $d$} is an element
$f \in \mathbb{Z}[[\{x_n\}_{n \in \mathbb{N}_{>0}}]]_{(d)}^{S_{\mathbb{N}}}$.
Let $\mathsf{SF}^d$ be the subgroup of
homogeneous symmetric functions of degree $d$.

We define the \emph{ring of symmetric functions} as the direct sum
\[
\mathsf{SF} = \bigoplus_{d \ge 0} \mathsf{SF}^d,
\]
which is a graded subring of $\mathbb{Z}[[\{x_n\}_{n \in \mathbb{N}_{>0}}]]$.

\begin{remark}
Note that ``symmetric function'' is standard terminology,
but it's not a great name since it's not
really clear what it is a function \emph{of}.
Moreover, the term symmetric function is often used in the finite
variable case to discuss ``ordinary'' functions like $e^{x+y}$,
which are invariant under symmetries like $x \leftrightarrow y$.
\end{remark}

There are canonical surjective graded ring homomorphisms
$\rho_n : \mathsf{SF} \to \mathsf{SF}_n$, which are defined via
\[
\rho_n(f)(x_1,\ldots,x_n) = f(x_1,\ldots,x_n,0,0,\cdots) .
\]
Note that convergence is not an issue since all but finitely many monomials
will evaluate as zero.

\begin{remark}
One can equivalently define the ring of symmetric functions as an inverse
limit
\[
\mathsf{SF} = \lim_{\substack{\longleftarrow\\n}} \mathsf{SF}^n
\]
in the category of graded rings (see \cite{Macdonald}).
(Warning: it is \emph{not} the inverse limit in ordinary rings.)
The $\rho_n$ above are precisely the canonical projections obtained from
this construction.
\end{remark}

We define the \emph{monomial symmetric function associated to $\lambda$}
given by
\[
m_\lambda := \sum_{\alpha} x^\alpha
\]
where $(\alpha_1,\ldots) \in \mathbb{N}^{\mathbb{N}_{>0}}$ ranges over all
\emph{distinct} permutations of $(\lambda_1,\ldots)$.
Observe that the set $\{ m_\lambda \mid \lambda \in
\operatorname{Par}\}$ is a basis for $\mathsf{SF}$.

We can now define the \emph{elementary symmetric functions}
\[
e_d = m_{1^d},
\]
the \emph{complete homogeneous symmetric functions}
\[
h_d = \sum_{\lambda \vdash d} m_\lambda ,
\]
and the \emph{power sum symmetric functions}
\[
p_d = m_{d}.
\]

The overloading of $m_\lambda$, $e_d$, $h_d$, and $p_d$ to mean
different objects in each $\mathsf{SF}^n$ is seen to be mostly harmless
in view of the fact that they are precisely the images of the
corresponding objects in $\mathsf{SF}$ under the maps to $\rho_n$.

We may also define the \emph{Schur symmetric functions}
$s_\lambda$ by observing that the Schur polynomials are compatible
with the construction of $\mathsf{SF}$ as an inverse limit.

\begin{proposition} \label{prop:fund_rel}
$\displaystyle\sum_{i=0}^d (-1)^i e_i h_{d-i}=0$ for every $d \ge 1$.
\end{proposition}

\begin{proof}
Consider the generating functions
\[ E(t) = \sum_{r \ge 0} e_r t^r
\textrm{ and }
H(t) = \sum_{r \ge 0} h_r t^r \]
as elements in $\mathsf{SF}[[t]]$.
We see that
\begin{align*}
& E(t)\\
 =& 1 + (x_1+x_2+\cdots)t
+ (x_1x_2+x_1x_3+\cdots)t^2 \\
=&\prod_{i \ge 1} (1+x_i t)
\end{align*}
in the larger ring $\mathbb{Z}[[x_1,\ldots]][[t]]$.
Similarly, recalling the geometric series formula, we have
\[
H(t) = \prod_{i \ge 1} (1-x_i t)^{-1} .
\]
The equality $H(t)E(-t)=1$ is immediate.
The desired identities are simply the coefficients of $t^d$
in this equality.
\end{proof}

\begin{proposition}[Newton Identities] For all $d \ge 1$,
\begin{align*}
dh_d&=\sum_{i=1}^d p_i h_{d-i} \textrm{ and} \\ 
de_d&=\sum_{i=1}^d (-1)^{i-1} p_i e_{d-i}.
\end{align*}
\end{proposition}

\begin{proof}
We compute
\begin{align*}
\sum_{r \ge 1} p_r t^{r-1}
&= \sum_{i \ge 1} \sum_{d \ge 0} x_i^d t^{d-1}
= \sum_{i \ge 1} \frac{x_i}{1-x_it}\\
&= \sum_{i \ge 1} \frac{d}{dt}\log\left(
\left(1-x_i\right)^{-1}\right)
= \frac{H'(t)}{H(t)} = \frac{E'(-t)}{E(-t)}
\end{align*}
and then we read the identities off from 
the coefficients of $t^d$ in $P(t)H(t)=H'(t)$
and $P(t)E(-t)=E'(-t)$.
\end{proof}

For $\lambda=(\lambda_1,\lambda_2,\ldots,\lambda_r)$ we define
$e_\lambda = e_{\lambda_1}\cdot e_{\lambda_2} \cdots e_{\lambda_r}$,
$h_\lambda = h_{\lambda_1}\cdot h_{\lambda_2} \cdots h_{\lambda_r}$, and
$p_\lambda = p_{\lambda_1}\cdot p_{\lambda_2} \cdots p_{\lambda_r}$.

We have a natural partial ordering on partitions where $\lambda \ge \mu$
if and only if
$\lambda_1 + \cdots + \lambda_i \ge \mu_1 + \cdots \mu_i$
for all $i \ge 1$.
(Note this is only a partial ordering as, for example, $(31^3)$ and $(2^3)$
are incomparable.

\begin{proposition} \label{prop:01matrix}
We have
\[
e_\lambda = \sum_{\mu \vdash |\lambda|} M_{\lambda \mu} m_\mu
\]
where $M_{\lambda \mu}$ is the number of $\{0,1\}$-matrices whose
rows sum to $\lambda_1,\lambda_2,\ldots$ and whose columns
sum to $\mu_1,\mu_2,\ldots$.
Moreover, $M_{\lambda\mu} \ne 0$ if and only if $\mu \le \lambda'$
and $M_{\lambda\lambda'}=1$.
\end{proposition}

\begin{proof}
We merely sketch the argument.
We consider the terms of $e_\lambda$ and $m_\mu$ in reference to the
following matrix:
\[
X = \begin{pmatrix}
x_1 & x_2 & x_3 & \cdots \\
x_1 & x_2 & x_3 & \cdots \\
x_1 & x_2 & x_3 & \cdots \\
\vdots & \vdots & \vdots & \ddots
\end{pmatrix}.
\]
Observe that each $\{0,1\}$-matrix $Y$ produces a monomial $x^\alpha$
by taking the product of the entries of $X$ corresponding to the
non-zero entries of $Y$.
Monomials in $e_\lambda$ are uniquely constructed by
taking the product of exactly $\lambda_1$ distinct entries from row $1$,
exactly $\lambda_2$ from row $2$, etc.
Monomials $x^\mu$ are constructed by
taking the product of exactly $\mu_1$ distinct entries from column $1$,
exactly $\mu_2$ from column $2$, etc.

The conditions on $M_{\lambda\mu}$ now follow by looking for
$\{0,1\}$-matrices satisfying certain constraints.
\end{proof}

After refining our partial order to a total order
on the partitions, we can think of $M=\left(M_{\lambda\mu}\right)$ as
an infinite integer matrix.
Note that $M_{\lambda\mu'}$ is triangular with $1$s along the diagonal.
Thus $M$ is invertible and we have the following important corollary:

\begin{corollary}[Fundamental Theorem of Symmetric Functions]
There is an equality of rings
\[\mathsf{SF} = \mathbb{Z}[e_1,e_2,\ldots] \]
where $e_1,e_2,\ldots$ are algebraically independent.
\end{corollary}

\begin{exercise}
Find an analog for Proposition~\ref{prop:01matrix} for $h_\lambda$
using $\mathbb{N}$-matrices instead of $\{0,1\}$-matrices.
Conclude that 
$\mathsf{SF} = \mathbb{Z}[h_1,h_2,\ldots]$
where $h_1,h_2,\ldots$ are algebraically independent.
\end{exercise}

\begin{exercise}
Use the Newton identites to show that 
$\mathsf{SF} \otimes_{\mathbb{Z}} \mathbb{Q} \cong \mathbb{Q}[p_1,p_2,\ldots]$
where $p_1,p_2,\ldots$ are algebraically independent.
\end{exercise}

\begin{example}
\[
\begin{pmatrix} e_{11}\\ e_2\\ e_{111}\\ e_{21}\\ e_3\\
e_{1111}\\ e_{211} \\ e_{22}\\ e_{31}\\ e_4
\end{pmatrix}
=
\begin{pmatrix}
2 & 1 &
 & & &
& & & & \\
1 & &
 & & &
& & & & \\
 & &
6 & 3 & 1 &
& & & & \\
 & &
3 & 1 & &
& & & & \\
 & &
1 & & &
& & & & \\
 & &
 & & &
24 & 12 & 6 & 4 & 1 \\
 & &
 & & &
12 & 5 & 2 & 1 & \\
 & &
 & & &
6 & 2 & 1 & & \\
 & &
 & & &
4 & 1 & & & \\
 & &
 & & &
1 & & & &
\end{pmatrix} 
\begin{pmatrix} m_{11}\\ m_2\\ m_{111}\\ m_{21}\\ m_3\\
m_{1111}\\ m_{211} \\ m_{22}\\ m_{31}\\ m_4
\end{pmatrix}
\]
\end{example}

\begin{example}
\[
\begin{pmatrix} h_{11}\\ h_2\\ h_{111}\\ h_{21}\\ h_3\\
h_{1111}\\ h_{211} \\ h_{22}\\ h_{31}\\ h_4
\end{pmatrix}
=
\begin{pmatrix}
2 & 1 &
 & & &
& & & & \\
1 & 1 &
 & & &
& & & & \\
 & &
6 & 3 & 1 &
& & & & \\
 & &
3 & 2 & 1 &
& & & & \\
 & &
1 & 1 & 1 &
& & & & \\
 & &
 & & &
24 & 12 & 6 & 4 & 1 \\
 & &
 & & &
12 & 7 & 4 & 3 & 1 \\
 & &
 & & &
6 & 4 & 3 & 2 & 1 \\
 & &
 & & &
4 & 3 & 2 & 2 & 1 \\
 & &
 & & &
1 & 1 & 1 & 1 & 1
\end{pmatrix} 
\begin{pmatrix} m_{11}\\ m_2\\ m_{111}\\ m_{21}\\ m_3\\
m_{1111}\\ m_{211} \\ m_{22}\\ m_{31}\\ m_4
\end{pmatrix}
\]
\end{example}

\begin{example}
\[
\begin{pmatrix} e_{11}\\ e_2\\ e_{111}\\ e_{21}\\ e_3\\
e_{1111}\\ e_{211} \\ e_{22}\\ e_{31}\\ e_4
\end{pmatrix}
=
\begin{pmatrix}
1 & &
 & & &
& & & & \\
\frac{1}{2} & -\frac{1}{2} &
 & & &
& & & & \\
 & &
1 & & &
& & & & \\
 & &
\frac{1}{2} & -\frac{1}{2} &  &
& & & & \\
 & &
\frac{1}{6} & -\frac{1}{2} & \frac{1}{3} &
& & & & \\
 & &
 & & &
1 & & & & \\
 & &
 & & &
\frac{1}{2} & -\frac{1}{2} & & & \\
 & &
 & & &
\frac{1}{4} & -\frac{1}{2} & \frac{1}{4} & & \\
 & &
 & & &
\frac{1}{6} & -\frac{1}{2} & & \frac{1}{3} & \\
 & &
 & & &
\frac{1}{24} & -\frac{1}{4} & \frac{1}{8} & \frac{1}{3} & -\frac{1}{4}
\end{pmatrix} 
\begin{pmatrix}
p_{11}\\ p_2\\ p_{111}\\ p_{21}\\ p_3\\
p_{1111}\\ p_{211} \\ p_{22}\\ p_{31}\\ p_4
\end{pmatrix}
\]
\end{example}

We end this section with a handful of interesting observations and
definitions (without proof) that hopefully will encourage the reader to
delve more deeply into \cite{Macdonald} and \cite{Stanley2}.

We have the formulas
\[
h_d = \sum_{\lambda \vdash d} \frac{p_\lambda}{z_\lambda}\]
and
\[
e_d = \sum_{\lambda \vdash d} \epsilon_\lambda
\frac{p_\lambda}{z_\lambda}
\]
where $\epsilon_\lambda = (-1)^{|\lambda|-\ell(\lambda)}$

There is a standard symmetric positive definite bilinear form $(-,-)$
on $\mathsf{SF}$ defined via
\[
( s_\lambda, s_\mu ) = \delta_{\lambda \mu}
\]
for all partitions $\lambda, \mu$.
This form also satisfies
\[
( h_\lambda, m_\mu ) = \delta_{\lambda \mu}
\]
and
\[
( p_\lambda, p_\mu ) = z_\lambda \delta_{\lambda \mu}
\]
for all partitions $\lambda, \mu$.

A consequence of the Fundamental Theorem is that there is a ring
isomorphism
\[
\omega : \mathsf{SF} \to \mathsf{SF}
\]
given by $\omega(e_\lambda)=h_\lambda$ for every partition $\lambda$.
In view of Proposition~\ref{prop:fund_rel}, we see that
$\omega(h_\lambda)=e_\lambda$ as well.
With a bit more work, one can show that
$\omega(p_\lambda)=\epsilon_\lambda p_\lambda$
and
$\omega(s_\lambda)=s_{\lambda'}$.
This last observation show us that $\omega$ is an isometry:
that $( \omega(f), \omega(g) ) = (f, g)$ for
all $f,g \in \mathsf{SF}$.

\section{Representations of Symmetric Groups}

Let $S_n$ be the symmetric group on $n$ letters.
Recall that the conjugacy classes of $S_n$ are in bijection with
partitions of $n$ by taking their cycle types.
Given a partition $\lambda \vdash n$ and a class function
$f \in C(S_n)$, we define $f(\lambda):=f(\sigma)$ where
$\sigma \in S_n$ is any permutation with cycle type $\lambda$.
Let $\chi_\lambda \in C(S_n)$ denote the characteristic function
\[
\chi_\lambda(\sigma)
\begin{cases}
1 & \textrm{if $\sigma$ has cycle type $\lambda$,}\\
0 & \textrm{otherwise.}\\
\end{cases}
\]

\begin{theorem}
There is a isometric group isomorphism
\[
\operatorname{ch} : R(S_n) \to \mathsf{SF}^n
\]
defined by
\[
\operatorname{ch}(f) :=
\sum_{\lambda \vdash n} \frac{f(\lambda)}{z_\lambda} p_{\lambda}.
\]
Given a class function $f$, its values can be computed via
\[
f(\lambda) = ( \operatorname{ch}(f), p_\lambda ).
\]
The characteristic functions $\chi_\lambda \in C(S_n)$
correspond to $\frac{p_{\lambda}}{z_\lambda}$ in
$\mathsf{SF}^n_{\mathbb{Q}}$.
The irreducible characters in $R(S_n)$ correspond to the Schur
functions $\{ s_\lambda \mid \lambda \vdash n \}$,
the trivial character corresponds to $h_n=s_n$, and
the sign character corresponds to $e_n=s_{(1)^n}$.
The involution $\omega : \mathsf{SF}^n \to \mathsf{SF}^n$
corresponds to tensoring with the sign character.
\end{theorem}

\begin{proof}
First we define the \emph{characteristic map}
$\operatorname{ch} : C(S_n) \to
\mathsf{SF}^n \otimes_{\mathbb{Z}} \mathbb{C}$
since it's not clear that the image of $R(S_n)$ is even
contained in $\mathsf{SF}^n$.
Recalling that $(p_\lambda,p_\mu)=z_\lambda \delta_{\mu \lambda}$,
the formula
\[
f(\lambda) = ( \operatorname{ch}(f), p_\lambda )
\]
is immediate.  This shows that $\operatorname{ch}$ is bijective
(on complex vector spaces).

The correspondence between
$\chi_\lambda$ and $\frac{p_{\lambda}}{z_\lambda}$
follow now from the observation that
\[
\chi_\lambda(\mu) = \delta_{\lambda \mu} =
\left(\frac{p_{\lambda}}{z_\lambda}, p_\mu\right)
\]
for all $\lambda$ and $\mu$.

Now, recall that the number of elements in $S_n$ with cycle type
$\lambda$ is given by $\frac{n!}{z_\lambda}$.  Thus
\[
(\chi_\lambda, \chi_\mu) =
\begin{cases}
\frac{1}{z_\lambda} & \textrm{if $\lambda=\mu$,}\\
0 & \textrm{otherwise.}\\
\end{cases}
\]
But this is exactly the same as $(p_\lambda,p_\mu)$,
so $\operatorname{ch}$ is an isometry.

We omit the proof of the remaining statements. 
\end{proof}

An immediate corollary of the above theorem is that
character table of $S_n$ is precisely the same
as the change of basis matrix between the $\{ p_\lambda \}$
and $\{ s_\lambda \}$ in $\mathsf{SF}_n$.

\begin{definition}
The irreducible representation $V_\lambda$ of $S_n$ corresponding to
$s_\lambda$ is the \emph{Specht module} associated to $\lambda$.
\end{definition}

Defining the graded group
\[
R(S_\ast) := \bigoplus_{n \ge 0} R(S_n)
\]
we obtain a characteristic map
\[
\operatorname{ch} : R(S_\ast) \to \mathsf{SF}
\]
by adding together graded components.
However, the ``obvious'' multiplication on $R(S_\ast)$
\emph{does not} correspond to the multiplication on $\mathsf{SF}$.
We define a multiplication on $R(S_\ast)$ that makes
$\operatorname{ch}$ into a graded ring isomorphism.

There is a natural embedding $S_n \times S_m \hookrightarrow S_{n+m}$;
there are many ways of doing this, but they are all conjugate.
Given a representation $\rho$ of $S_n$, we obtain a representation
$\widetilde{\rho}$ of $S_n \times S_m$ from $\rho$ by precomposition
with the first projection.  Similarly, given a representation $\sigma$
of $S_m$, we obtain a representation $\widetilde{\sigma}$ of
$S_n \times S_m$.

Let $R(S_n)$ be the representation ring of the symmetric group $S_n$. 
We define a bilinear multiplication
\[ \boxtimes : R(S_n) \times R(S_m) \to R(S_{n+m}) \]
via
\[
\rho \boxtimes \sigma := \operatorname{Ind}_{S_n \times S_m}^{S_{n+m}}
(\widetilde{\rho} \otimes \widetilde{\sigma}).
\]
This turns $R(S_\ast)$ into a commutative, graded ring
and $\operatorname{ch}$ is a graded ring isomorphism.

\subsection{Explicit Description of Specht modules}

Here we actually construct each Specht module $V_\lambda$
as a subrepresentation of the regular representation of $S_n$.
Note that the isotypic component associated to $V_\lambda$ usually has
multiplicity greater than $1$, so the construction unsurprisingly relies
on an arbitrary choice.

\begin{definition}
A \emph{Young tableau} $T$ is a Young diagram for a partition $\lambda$
of $n$ where each number in $\{1,\ldots,n\}$ is assigned to exactly one
box.
Given a Young tableau $T$, we define $P_T$ as the
subgroup of $S_n$ that permutes only the numbers within each row of $T$
and $Q_T$ as the subgroup that permutes only the numbers within each
column of $T$.  
\end{definition}

\begin{example}
The following is a Young tableau for the partition $322$:
\begin{center}
\begin{ytableau}
3 & 1 & 5 \\
6 & 2 \\
4 & 7
\end{ytableau}
\end{center}
We have
\[
P_T = S_{\{1,3,5\}} \times S_{\{2,6\}} \times S_{\{4,7\}}
\textrm{ and }
Q_T = S_{\{3,4,6\}} \times S_{\{1,2,7\}}
\]
where $S_X$ is the group of permutations of the set $X$. 
\end{example}

If $\lambda = (\lambda_1,\ldots,\lambda_r)$ is a partition,
define $S_\lambda := S_{\lambda_1} \times \cdots \times S_{\lambda_r}$.
Observe that $P_T \cong S_\lambda$
and $Q_T \cong S_{\lambda'}$.
The subgroups $P_T$ and $Q_T$ depend on the choice of tableau $T$, but
the conjugacy class only depends on the corresponding partition
$\lambda$.

Given a Young tableau $T$ and a representation $V$ of $S_n$,
define the \emph{Young projectors}:
\[
a_T := \frac{1}{|P_T|}\sum_{\sigma \in P_T} \sigma
\textrm{ and }
b_T := \frac{1}{|Q_T|}\sum_{\sigma \in Q_T} \epsilon(\sigma)\sigma
\]
which are easily seen to be projections in $\operatorname{End}(V)$.
The \emph{Young symmetrizer} is the endomorphism $c_T = a_T \circ b_T$.
One checks that $c_T = b_T \circ a_T$.

\begin{theorem}
Suppose $\lambda$ is a partition of $n$.
If $V_{reg}$ is the regular representation and $T$ is a Young tableau
for $\lambda$, then the image of $c_T(V_{reg})$ is isomorphic to the
Specht module $V_\lambda$.
\end{theorem}

\begin{proof}
We only sketch this.
First, let $U_T = a_T(V_{reg})$ and $W_T = b_T(V_{reg})$.
We observe that
\[
U_T \cong \operatorname{Ind}_{P_T}^{S_n} 1_{P_T}
\]
and
\[
W_T \cong \operatorname{Ind}_{Q_T}^{S_n} \epsilon_{Q_T}
\]
where $1_{P_T}$ is the trivial representation and $\epsilon_{Q_T}$ is the sign
representation.
In other words, the characteristic of $U_T$ is
\[
\operatorname{ch}(1 \boxtimes \cdots \boxtimes 1)
= h_{\lambda_1} \cdots h_{\lambda_r} = h_\lambda,
\]
while the characteristic of $W_T$ is
\[
\operatorname{ch}(\epsilon \boxtimes \cdots \boxtimes \epsilon)
= e_{\lambda'_1} \cdots e_{\lambda'_r} = e_{\lambda'}.
\]
Writing out $h_\lambda$ and $e_{\lambda'}$ in the Schur basis,
we see that $s_\lambda$ is the only basis vector with a non-zero entry
in both.
Moreover, $(s_\lambda,h_\lambda)=(s_\lambda,e_{\lambda'})=1$.
Thus, the image $a_T \circ b_T$ is isomorphic to the Specht module
$V_\lambda$ provided the image is non-zero.

Let $\{ v_\sigma \}_{\sigma \in S_n}$ be the standard basis for the regular
representation $V_{reg}$.
We have the concrete description
\[
c_T(v_{1})  = \frac{1}{|P_T| |Q_T|}\sum_{\sigma \in P_T}\sum_{\tau \in Q_T}
\epsilon(\tau) v_{\sigma\tau} .
\]
Since $P_T \cap Q_T = \{1\}$, the $v_{\sigma\tau}$ are all distinct.
Thus $c_T(x) \ne 0$ as desired.
\end{proof}

\bibliographystyle{alpha}
\bibliography{rep_theory}

\end{document}


